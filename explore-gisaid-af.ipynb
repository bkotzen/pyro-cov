{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring GISAID alignment-free clustering\n",
    "\n",
    "This explores a low-dimensional embedding constructed via AMS sketches of k-mers. To run this notebook, first get GISAID data (sign agreement, set up feed, ...), then run\n",
    "```sh\n",
    "python preprocess_gisaid.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pyrocov.cluster import ClockSketcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.load(\"results/gisaid.sketch.pt\")\n",
    "sketch = result[\"sketch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sketch.count.float().numpy(), bins=100)\n",
    "plt.title(f\"mean k-mer count = {sketch.count.float().mean():0.1f}\")\n",
    "plt.yscale(\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = sketch[torch.randperm(len(sketch))[:200]]\n",
    "sketcher = ClockSketcher(20)\n",
    "diffs, std = sketcher.estimate_set_difference(batch, batch)\n",
    "d = diffs.reshape(-1)\n",
    "l = (batch.count[:, None] - batch.count).float()\n",
    "\n",
    "plt.scatter(l, d, lw=0, alpha=0.01)\n",
    "plt.plot([0, l.max()], [0, l.max()], \"k--\", lw=1)\n",
    "plt.plot([l.min(), 0], [0, 0], \"k--\", lw=1)\n",
    "plt.xlabel(\"|x| - |y|\")\n",
    "plt.ylabel(r\"|x \\ y|\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = torch.load(\"results/gisaid.cluster.pt\")\n",
    "full_clusters = clustering[\"full_clusters\"]\n",
    "full_weights = clustering[\"full_weights\"]\n",
    "clusters = clustering[\"clusters\"]\n",
    "weights = clustering[\"weights\"]\n",
    "class_probs = clustering[\"class_probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(full_weights)\n",
    "plt.xlabel(\"cluster rank\")\n",
    "plt.ylabel(\"cluster size\")\n",
    "plt.yscale(\"log\")\n",
    "p = full_weights / full_weights.sum()\n",
    "perplexity = p.log().neg().mul(p).sum().exp()\n",
    "plt.title(f\"weight = {full_weights.sum():0.1f}, perplexity = {perplexity:0.2f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_result = torch.load(\"results/gisaid.sketch.pt\")\n",
    "day = torch.tensor(sketch_result[\"columns\"][\"day\"], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(day.numpy(), bins=200)\n",
    "plt.yscale(\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain = class_probs.max(-1).indices\n",
    "# strain = class_probs.multinomial(1)  # Extremely slow.\n",
    "week = day // 7\n",
    "num_weeks = 1 + int(week.max())\n",
    "num_strains = class_probs.size(-1)\n",
    "counts = torch.zeros(num_strains, num_weeks)\n",
    "i = strain * num_weeks + week\n",
    "counts.reshape(-1).scatter_add_(0, i, torch.tensor(1.).expand_as(i))\n",
    "\n",
    "plt.figure(figsize=(8, 4), dpi=300)\n",
    "plt.plot(counts.T, lw=1)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"week after 2019-12-01\")\n",
    "plt.ylabel(\"samples / week\")\n",
    "plt.title(f\"{num_strains} clusters\")\n",
    "plt.xlim(0, num_weeks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM model based on sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.autoguide import AutoDelta, init_to_sample\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.optim import Adam\n",
    "from pyro.ops.indexing import Vindex\n",
    "import pyro.poutine as poutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.load(\"results/gisaid.sketch.pt\")\n",
    "sketch = result[\"sketch\"]\n",
    "\n",
    "data = (sketch.clocks - sketch.clocks[0])[:, :128].float()\n",
    "data -= data.mean(0)\n",
    "data /= data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components(data):\n",
    "    h = data[torch.randperm(len(data))[:2000]]\n",
    "    mean = h.mean(0)\n",
    "    std = h.std(0)\n",
    "    bits = h.size(-1)\n",
    "    rows = int((bits/2) ** 0.5)\n",
    "    fig, axes = plt.subplots(rows, (bits // 2 + rows - 1) // rows, figsize=(12, 12), dpi=200)\n",
    "    axes = [a for a_ in axes for a in a_]\n",
    "    for ax in axes:\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "    i = 0\n",
    "    for ax in axes:\n",
    "        j = i + 1\n",
    "        if j >= bits:\n",
    "            break\n",
    "        x, y = h[:, i], h[:, j]\n",
    "        ax.scatter(x, y, lw=0, alpha=0.01)\n",
    "        ax.set_xlim(mean[i] - 3 * std[i], mean[i] + 3 * std[i])\n",
    "        ax.set_ylim(mean[j] - 3 * std[j], mean[j] + 3 * std[j])\n",
    "        i += 2\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "plot_components(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def model(num_clusters, data):\n",
    "    scale_tril = pyro.param(\"scale_tril\",\n",
    "                            lambda: torch.eye(data.size(-1)),\n",
    "                            constraint=constraints.lower_cholesky)\n",
    "    \n",
    "    loc = pyro.sample(\"loc\",\n",
    "                      dist.Normal(0, data.size(-1) ** (-0.5))\n",
    "                          .expand([num_clusters, data.size(-1)])\n",
    "                          .to_event(2)\n",
    "                          .mask(False))\n",
    "    weights = pyro.sample(\"weights\", dist.Dirichlet(torch.full((num_clusters,), 2.)))\n",
    "    with pyro.plate(\"data\", len(data), subsample_size=256) as ind:\n",
    "        c = pyro.sample(\"component\", dist.Categorical(weights))\n",
    "        pyro.sample(\"locs\", dist.MultivariateNormal(loc[c], scale_tril=scale_tril),\n",
    "                    obs=data[ind])\n",
    "\n",
    "num_clusters = 50\n",
    "guide = AutoDelta(poutine.block(model, hide=[\"component\"]),\n",
    "                  init_loc_fn=init_to_sample)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(20201223)\n",
    "svi = SVI(model, guide, Adam({\"lr\": 0.05}), TraceEnum_ELBO(max_plate_nesting=1))\n",
    "losses = []\n",
    "for step in range(1001):\n",
    "    loss = svi.step(num_clusters, data) / data.numel()\n",
    "    losses.append(loss)\n",
    "    if step % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            p = guide.median()[\"weights\"]\n",
    "            perplexity = p.log().neg().mul(p).sum().exp()\n",
    "        print(f\"step {step: >4d} loss = {loss:0.3g}\\tperplexity = {perplexity:0.2f}\")\n",
    "plt.figure(figsize=(8, 3), dpi=300)\n",
    "plt.plot(losses, lw=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    median = guide.median()\n",
    "    print(pyro.param(\"scale_tril\"))\n",
    "    print(median[\"loc\"][:, 0].data.numpy())\n",
    "    print(median[\"weights\"].data.sort(0, descending=True).values.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plot_components(data @ pyro.param(\"scale_tril\").T.inverse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
