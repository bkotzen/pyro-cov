{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for mutation-transmissibility paper\n",
    "\n",
    "This notebook generates plots for the [paper/](paper/) directory. This assumes you've alread run\n",
    "```sh\n",
    "make update        # ~10 minutes on CPU (mostly sequence alignment)\n",
    "python mutrans.py  # ~2 hours on GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import logging\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyrocov import mutrans, pangolin, stats\n",
    "from pyrocov.stats import normal_log10bf\n",
    "from pyrocov.util import pretty_print\n",
    "\n",
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "matplotlib.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'Avenir', 'DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    y = (y - x.mean()) / y.std()\n",
    "    return (x * y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def load_data():\n",
    "    filename = \"results/mutrans.data.single.pt\"\n",
    "    if os.path.exists(filename):\n",
    "        dataset = torch.load(filename)\n",
    "    else:\n",
    "        dataset = mutrans.load_gisaid_data()\n",
    "        torch.save(dataset, filename)\n",
    "    dataset.update(mutrans.load_jhu_data(dataset))\n",
    "    return dataset\n",
    "dataset = load_data()\n",
    "locals().update(dataset)\n",
    "for k, v in sorted(dataset.items()):\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k} \\t{type(v).__name__} of shape {tuple(v.shape)}\")\n",
    "    else:\n",
    "        print(f\"{k} \\t{type(v).__name__} of size {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} x {} x {} = {}\".format(*weekly_strains.shape, weekly_strains.shape.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "print(\"Loaded data from {} samples\".format(len(columns[\"lineage\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checking case count time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(weekly_cases, lw=1, alpha=0.5)\n",
    "    plt.yscale(\"symlog\", linthresh=10)\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlim(0, len(weekly_cases) - 1)\n",
    "    plt.xlabel(\"week after 2019-12-01\")\n",
    "    plt.ylabel(\"confirmed cases\");\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(weekly_strains.sum(-1), lw=1, alpha=0.5)\n",
    "    plt.yscale(\"symlog\", linthresh=10)\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlim(0, len(weekly_cases) - 1)\n",
    "    plt.xlabel(\"week after 2019-12-01\")\n",
    "    plt.ylabel(\"sequenced samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set(location_id)\n",
    "N_usa = sum(1 for k in locations if \"/ USA /\" in k)\n",
    "N_uk = sum(1 for k in locations if \"/ United Kingdom /\" in k)\n",
    "N_other = len(locations) - N_usa - N_uk\n",
    "print(N_usa, N_uk, N_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll account for epidemiological dynamics in the form of random drift on top of our logistic growth model. Since random drift is inversely proportional to the local number of infections, we'll need a new data source for the number of infections in each region. We'll use JHU's confirmed case counts time series as a proxy for the number of total infections in each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = torch.load(\"results/mutrans.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in fits:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit = list(fits.values())[0]\n",
    "pretty_print(best_fit, max_items=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale `rate_coef` by 1/100 in all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALREADY_SCALED = set()\n",
    "\n",
    "def scale_tensors(x, names={\"rate_coef\", \"rate_bias\"}, scale=0.01, prefix=\"\"):\n",
    "    if id(x) in ALREADY_SCALED:\n",
    "        return\n",
    "    if isinstance(x, dict):\n",
    "        for k, v in list(x.items()):\n",
    "            if k in names:\n",
    "                print(f\"{prefix}.{k}\")\n",
    "                x[k] = v * scale\n",
    "            elif k == \"diagnostics\":\n",
    "                continue\n",
    "            else:\n",
    "                scale_tensors(v, names, scale, f\"{prefix}.{k}\")\n",
    "    ALREADY_SCALED.add(id(x))\n",
    "                \n",
    "scale_tensors(fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assess model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_fits():\n",
    "    num_nonzero = int(torch.count_nonzero(weekly_strains))\n",
    "    for key, fit in fits.items():\n",
    "        median = fit.get(\"median\", fit.get(\"mean\", {}))\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        time = np.arange(1, 1 + len(fit[\"losses\"]))\n",
    "        plt.plot(fit[\"losses\"], \"k--\", label=\"loss\")\n",
    "        locs = []\n",
    "        grads = []\n",
    "        for name, series in fit[\"series\"].items():\n",
    "            rankby = -torch.tensor(series).log1p().mean().item()\n",
    "            if name.startswith(\"Guide.\"):\n",
    "                name = name[len(\"Guide.\"):].replace(\"$$$\", \".\")\n",
    "                grads.append((name, series, rankby))\n",
    "            elif re.search(\"_[0-9]+_[0-9]+$\", name):\n",
    "                grads.append((name, series, rankby))\n",
    "            elif name != \"loss\":\n",
    "                locs.append((name, series, rankby))\n",
    "        locs.sort(key=lambda x: x[-1])\n",
    "        grads.sort(key=lambda x: x[-1])\n",
    "        for name, series, _ in locs:\n",
    "            plt.plot(time, series, label=name)\n",
    "        for name, series, _ in locs:\n",
    "            plt.plot(time, series, color=\"white\", lw=3, alpha=0.3, zorder=-1)\n",
    "        for name, series, _ in grads:\n",
    "            plt.plot(time, series, lw=1, alpha=0.3, label=name, zorder=-2)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlim(1, len(fit[\"losses\"]))\n",
    "        plt.legend(loc=\"upper left\", fontsize=8)\n",
    "        plt.xlabel(\"SVI step (duration = {:0.1f} minutes)\".format(fit[\"walltime\"]/60))\n",
    "        loss = np.median(fit[\"losses\"][-201:]) / num_nonzero\n",
    "        scalars = \" \".join([f\"L={loss:0.6g}\"] + [\n",
    "            \"{}={:0.3g}\".format(\n",
    "                \"\".join(p[0] for p in k.split(\"_\")).upper(), v\n",
    "            )\n",
    "            for k, v in median.items()\n",
    "            if v.numel() == 1\n",
    "        ])\n",
    "        plt.title(\"{} ({})\\n{}\".format(key[0], scalars, key[-1]))\n",
    "plot_fits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plusminus(mean, std):\n",
    "    p95 = 1.96 * std\n",
    "    return torch.stack([mean - p95, mean, mean + p95])\n",
    "\n",
    "def plot_forecast(fit, queries=None, num_strains=10, filenames=[]):\n",
    "    if queries is None:\n",
    "        queries = list(location_id)\n",
    "    elif isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    fig, axes = plt.subplots(len(queries), figsize=(8, 1.5 + 2 * len(queries)), sharex=True)\n",
    "    if not isinstance(axes, (list, np.ndarray)):\n",
    "        axes = [axes]\n",
    "    probs = plusminus(fit[\"mean\"][\"probs\"], fit[\"std\"][\"probs\"])\n",
    "    predicted = probs * weekly_cases[:, :, None]  # [T, P, S]\n",
    "    ids = torch.tensor([i for name, i in location_id.items()\n",
    "                        if any(q in name for q in queries)])\n",
    "    strain_ids = weekly_strains[:, ids].sum([0, 1]).sort(-1, descending=True).indices\n",
    "    strain_ids = strain_ids[:num_strains]\n",
    "    colors = [f\"C{i}\" for i in range(10)] + [\"black\"] * 90\n",
    "    assert len(colors) >= num_strains\n",
    "    light = \"#bbbbbb\"\n",
    "    for row, (query, ax) in enumerate(zip(queries, axes)):\n",
    "        ids = torch.tensor([i for name, i in location_id.items() if query in name])\n",
    "        print(f\"{query} matched {len(ids)} regions\")\n",
    "        counts = weekly_cases[:, ids].sum(1)\n",
    "        counts /= counts.max()\n",
    "        ax.plot(counts, \"k-\", color=light, lw=0.8, zorder=-20)\n",
    "        counts = weekly_strains[:, ids].sum([1, 2])\n",
    "        counts /= counts.max()\n",
    "        ax.plot(counts, \"k--\", color=light, lw=1, zorder=-20)\n",
    "        pred = predicted.index_select(-2, ids).sum(-2)\n",
    "        pred /= pred[1].sum(-1, True).clamp_(min=1e-8)\n",
    "        obs = weekly_strains[:, ids].sum(1)\n",
    "        obs /= obs.sum(-1, True).clamp_(min=1e-9)\n",
    "        time = np.arange(len(local_time))\n",
    "        for s, color in zip(strain_ids, colors):\n",
    "            lb, mean, ub = pred[..., s]\n",
    "            ax.fill_between(time, lb, ub, color=color, alpha=0.2, zorder=-10)\n",
    "            ax.plot(mean, color=color, lw=1, zorder=-9)\n",
    "            strain = lineage_id_inv[s]\n",
    "            ax.plot(obs[:, s], color=color, lw=0, marker='o', markersize=3,\n",
    "                    label={\"Q\": \"B.1.1.7\"}.get(strain, strain) if row == 0 else None)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks(())\n",
    "        ax.set_ylabel(query.replace(\" / \", \"\\n\"))\n",
    "        ax.set_xlim(0, len(weekly_strains))\n",
    "        if row == len(axes) - 1:\n",
    "            ax.set_xlabel(\"Time (week after 2019-12-01)\")\n",
    "        if row == 0:\n",
    "            ax.legend(loc=\"upper left\", fontsize=8)\n",
    "        elif row == 1:\n",
    "            ax.plot([], \"k--\", color=light, lw=1, label=\"relative #samples\")\n",
    "            ax.plot([], \"k-\", color=light, lw=0.8, label=\"relative #cases\")\n",
    "            ax.plot([], lw=0, marker='o', markersize=3, color='gray',\n",
    "                    label=\"observed portion\")\n",
    "            ax.fill_between([], [], [], color='gray', label=\"predicted portion\")\n",
    "            ax.legend(loc=\"upper left\", fontsize=8)\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "plot_forecast(best_fit,\n",
    "              queries=[\"England\"],\n",
    "              num_strains=10,\n",
    "              filenames=[\"paper/forecast.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_prevalence(fit, filenames=()):\n",
    "    rate = fit[\"median\"][\"rate\"]\n",
    "    if rate.dim() == 2:\n",
    "        rate = rate.median(0).values\n",
    "    rate = rate - rate[lineage_id[\"A\"]]\n",
    "    R = rate.exp()\n",
    "    probs = fit[\"median\"][\"probs\"].mean(0)\n",
    "    cases = torch.einsum(\"ps,p->s\", probs, weekly_cases[-2])\n",
    "    cases = cases / mutrans.TIMESTEP\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(R, cases, lw=0, alpha=0)\n",
    "    for name, i in lineage_id.items():\n",
    "        plt.text(R[i], cases[i], name, fontsize=8, alpha=0.8,\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",)\n",
    "    plt.ylabel(\"confirmed cases / day\")\n",
    "    plt.yscale(\"symlog\")\n",
    "    #plt.xscale(\"log\")\n",
    "    #plt.ylim(1, None)\n",
    "    plt.xlim(0.9, None)\n",
    "    lb10 = math.floor(10 * R.min().item())\n",
    "    ub10 = math.ceil(10 * R.max().item())\n",
    "    xticks = [x10 / 10 for x10 in range(lb10, ub10 + 1)]\n",
    "    plt.xticks(xticks, list(map(str, xticks)))\n",
    "    plt.xlabel(\"relative reproduction number $R_{strain} / R_A$\")\n",
    "    plt.title(f\"Transmissibility of {len(lineage_id)} PANGO lineages\")\n",
    "    plt.tight_layout()\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "plot_prevalence(best_fit, [\"paper/strain_prevalence.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_volcano(mean, std, filenames=(), linthresh=2, top_k=60):\n",
    "    xs = mean\n",
    "    ys = mean.abs() / std\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    ys, idx = ys.sort(0, descending=True)\n",
    "    xs = xs[idx]\n",
    "    pos = (0 < xs) & (xs < math.inf)\n",
    "    neg = (-math.inf < xs) & (xs < 0)\n",
    "    ys_pos, ys_neg = ys[pos], ys[neg]\n",
    "    xs_pos, xs_neg = xs[pos], xs[neg]\n",
    "    idx_pos, idx_neg = idx[pos], idx[neg]\n",
    "    N = top_k\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\")\n",
    "    for mask in [pos, neg]:\n",
    "        xs_mask, ys_mask = xs[mask], ys[mask]\n",
    "        plt.plot(xs_mask[:N], ys_mask[:N], 'k.', lw=0, markersize=2, zorder=10)\n",
    "        plt.plot(xs_mask[N:], ys_mask[N:], 'k.', lw=0, markersize=2, zorder=10, color=\"#aaa\")\n",
    "    plt.xlabel(\"effect size (R / R_A = exp(μ))\")\n",
    "    xticks = [0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15]\n",
    "    plt.xticks(list(map(math.log, xticks)), list(map(str, xticks)))\n",
    "    plt.ylabel(\"statistical significance (|μ|/σ)\")\n",
    "    lpad = 0.33 if any(\",\" in mutations[i] for i in idx_neg[:N].tolist()) else 0.18\n",
    "    rpad = 0.33 if any(\",\" in mutations[i] for i in idx_pos[:N].tolist()) else 0.18\n",
    "    plt.xlim(x0 - (x1 - x0) * lpad, x1 + (x1 - x0) * rpad)\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000] if y < y1]\n",
    "    plt.yticks(yticks, list(map(str, yticks)))\n",
    "    p95 = dist.Normal(0, 1).icdf(torch.tensor(0.95)).item()\n",
    "    plt.plot([x0, x1], [p95, p95], 'k--', alpha=0.2)\n",
    "    plt.text(0.2 * x0 + 0.8 * x1, p95 * 0.95, \"95% probabililty\\nof correct sign(μ)\",\n",
    "             fontsize=7, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "             alpha=0.8, zorder=100)\n",
    "        \n",
    "    colors = {\"N\": \"blue\", \"S\": \"red\", \"M\": \"purple\", \"ORF3a\": \"darkgreen\"}\n",
    "    ax = plt.gca()\n",
    "    t = (ax.transScale + ax.transLimits).inverted()\n",
    "    for i in range(N):\n",
    "        x = x0\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        plt.plot([x, xs_neg[i]], [y, ys_neg[i]], color='gray', lw=0.2)\n",
    "        name = mutations[int(idx_neg[i])]\n",
    "        plt.text(x, y, name + \" \", color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"right\")\n",
    "    for i in range(N):\n",
    "        x = x1\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        name = mutations[int(idx_pos[i])]\n",
    "        plt.plot([x, xs_pos[i]], [y, ys_pos[i]], color='gray', lw=0.2)\n",
    "        plt.text(x, y, \" \" + name, color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.tight_layout()\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_volcano(best_fit[\"mean\"][\"rate_coef\"], best_fit[\"std\"][\"rate_coef\"], linthresh=2,\n",
    "             filenames=[\"paper/volcano.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrocov.sarscov2 import GENE_TO_POSITION, aa_mutation_to_position\n",
    "\n",
    "def plot_manhattan(mean, std, top_k=75, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    even = (gene_ids % 2 == 0) & (mean > 0)\n",
    "    odd = (gene_ids % 2 == 1) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    mean_scale = 50 / mean.max().item()\n",
    "    for mask, color in zip([even, odd], [\"darkblue\", \"darkred\"]):\n",
    "        plt.scatter(position[mask].numpy(), sigma[mask].numpy(),\n",
    "                    mean_scale * mean[mask].numpy(), color=color, alpha=0.5, lw=0)\n",
    "    special = {\"S\": [], \"N\": [], \"ORF3a\": []}  # Many hits, plot with lines\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene in special:\n",
    "            special[gene].append((y, x, name))\n",
    "            continue\n",
    "        plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                 verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    for special_ in special.values():\n",
    "        special_.sort(reverse=True)\n",
    "    y_bounds = {k: (min(y for (y, _, _) in v), max(y for (y, _, _) in v))\n",
    "                for k, v in special.items() if v}\n",
    "    for i, (y, x, name) in enumerate(special[\"S\"]):\n",
    "        lb, ub = y_bounds[\"S\"]\n",
    "        lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "        y_label = 0.2 * y + 0.8 * (ub + (lb - ub) * (i / (len(special[\"S\"]) - 0.99)))\n",
    "        x_label = GENE_TO_POSITION[\"S\"][1] - 1000\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    for gene in [\"N\", \"ORF3a\"]:\n",
    "        for i, (y, x, name) in enumerate(special[gene]):\n",
    "            lb, ub = y_bounds[gene]\n",
    "            lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "            y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[gene]) - 0.99)))\n",
    "            x_label = GENE_TO_POSITION[gene][1] + 200\n",
    "            plt.text(x_label, y_label, name, fontsize=6,\n",
    "                     verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "            plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "        \n",
    "    start_end = list(GENE_TO_POSITION.values())\n",
    "    plt.xlim(start_end[0][0], start_end[-1][-1])\n",
    "    xticks = []\n",
    "    for i, (gene, (start, end)) in enumerate(GENE_TO_POSITION.items()):\n",
    "        if gene == \"ORF14\":\n",
    "            continue  # skip overlapping frame\n",
    "        plt.axvline(start, lw=0.1)\n",
    "        plt.axvline(end, lw=0.1)\n",
    "        xticks.extend([start, end])\n",
    "        plt.text((start + end) / 2, -y1 / 50, gene, rotation=-90,\n",
    "                 fontsize=6, verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "    plt.xticks(xticks, labels=())\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"μ / σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_manhattan(best_fit[\"mean\"][\"rate_coef\"], best_fit[\"std\"][\"rate_coef\"],\n",
    "               filenames=[\"paper/manhattan.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_upper_east_side(mean, std, top_k=120, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    mask = (gene_ids == gene_id[\"N\"]) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"Increased transmissibility of mutations within N gene\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    mean_scale = 50 / mean.max().item()\n",
    "    plt.scatter(position[mask].numpy(), sigma[mask].numpy(),\n",
    "                mean_scale * mean[mask].numpy(), color=\"darkblue\", alpha=0.5, lw=0)\n",
    "    special = []  # Many hits, plot with lines\n",
    "    z0 = 28800\n",
    "    z1 = 29000\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene != \"N\":\n",
    "            continue\n",
    "        if z0 < x < z1:\n",
    "            special.append((y, x, name))\n",
    "        else:\n",
    "            plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                     verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    special.sort(reverse=True)\n",
    "    lb = min(y for (y, _, _) in special)\n",
    "    ub = max(y for (y, _, _) in special)\n",
    "    lb, ub = lb * 0.5, ub * 0.5 + y1 * 0.5\n",
    "    for i, (y, x, name) in enumerate(special):\n",
    "        y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special) - 0.99)))\n",
    "        x_label = z1\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    start, end = GENE_TO_POSITION[\"N\"]\n",
    "    plt.xlim(start, end)\n",
    "    xticks = [start]\n",
    "    while xticks[-1] + 150 < end:\n",
    "        xticks.append(xticks[-1] + 150)\n",
    "    labels = [str((x - start) // 3) for x in xticks]\n",
    "    plt.xticks(xticks, labels)\n",
    "    plt.xlabel(\"amino acid position within N gene\")\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"μ / σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_upper_east_side(best_fit[\"mean\"][\"rate_coef\"], best_fit[\"std\"][\"rate_coef\"],\n",
    "                     filenames=[\"paper/upper_east_side.png\"], top_k=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a table of top mutations and their stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mutations(fit, names):\n",
    "    mean = fit[\"mean\"][\"rate_coef\"]\n",
    "    std = fit[\"std\"][\"rate_coef\"]\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    ranks = sigma.sort(0, descending=True).indices.tolist()\n",
    "    assert len(ranks) == len(mutations)\n",
    "    ranked = [mutations[k] for k in ranks]\n",
    "    ranks = {m: i for i, m in enumerate(ranked)}\n",
    "    print(\"Mut'n\\tRank\\tEstimate\")\n",
    "    for name in names:\n",
    "        i = mutations.index(name)\n",
    "        print(\"{}\\t{}\\t{:0.3g} ± {:0.2g}\".format(name, ranks[name], mean[i], std[i]))\n",
    "\n",
    "rank_mutations(best_fit, [\"S:D614G\", \"S:N501Y\", \"S:E484K\", \"S:L452R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_features = torch.zeros_like(features)\n",
    "for c, child in enumerate(lineage_id_inv):\n",
    "    child = pangolin.decompress(child)\n",
    "    parent = child\n",
    "    while True:\n",
    "        parent = \"A\" if parent == \"A\" else pangolin.get_parent(parent)\n",
    "        try:\n",
    "            p = lineage_id[pangolin.compress(parent)]\n",
    "            break\n",
    "        except KeyError:\n",
    "            continue\n",
    "    parent_features[c] = features[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emergences(i):\n",
    "    delta = features[:, i] - parent_features[:, i]\n",
    "    emerged = set((delta > 0.5).nonzero(as_tuple=True)[0].tolist())\n",
    "    emerged.add(delta.argmax().item())\n",
    "    result = []\n",
    "    for k in sorted(emerged):\n",
    "        name = lineage_id_inv[k]\n",
    "        longname = pangolin.decompress(name)\n",
    "        result.append(name if name == longname else f\"{name} ({longname})\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mutation_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    mean = fit[\"mean\"][\"rate_coef\"]\n",
    "    std = fit[\"std\"][\"rate_coef\"]\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    if \"samples\" in fit:\n",
    "        lb, ub = stats.confidence_interval(0.95, fit[\"samples\"][\"rate_coef\"])\n",
    "    else:\n",
    "        lb, ub = dist.Normal(mean, std).icdf(torch.tensor([0.025, 0.975])[:, None])\n",
    "    R_RA = mean.exp()  # mean is in units of generation time.\n",
    "    lineage_counts = weekly_strains.sum((0, 1))\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"mutation\", \"{:s}\"),\n",
    "        (\"mean/stddev\", \"{:0.6g}\"),\n",
    "        (\"mean\", \"{:0.6g}\"),\n",
    "        (\"95% ci lower\", \"{:0.6g}\"),\n",
    "        (\"95% ci upper\", \"{:0.6g}\"),\n",
    "        (\"R / R_A\", \"{:0.6g}\"),\n",
    "        (\"emerged in lineages\", \"{:s}\"),  \n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(sigma.sort(0, descending=True).indices.tolist()):\n",
    "            emerged = find_emergences(i)\n",
    "            f.write(row.format(\n",
    "                rank + 1, mutations[i],\n",
    "                sigma[i], mean[i], lb[i], ub[i], R_RA[i], \", \".join(emerged)\n",
    "            ))\n",
    "\n",
    "write_mutation_table(best_fit, \"paper/mutations.tsv\")\n",
    "pd.read_csv(\"paper/mutations.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lineage_bdays(exclude_first=10):\n",
    "    lineage_days = defaultdict(list)\n",
    "    for lineage, day in zip(columns[\"lineage\"], columns[\"day\"]):\n",
    "        lineage = pangolin.decompress(lineage)\n",
    "        lineage_days[lineage].append(day)\n",
    "    lineage_bday = {}\n",
    "    for lineage, days in list(lineage_days.items()):\n",
    "        days.sort()\n",
    "        lineage_bday[lineage] = days[min(exclude_first, len(days) // 10)]\n",
    "    start_date = datetime.datetime.strptime(mutrans.START_DATE, \"%Y-%m-%d\")\n",
    "    return {\n",
    "        lineage: (start_date + datetime.timedelta(days=day)).strftime(\"%Y-%m-%d\")\n",
    "        for lineage, day in lineage_bday.items()\n",
    "    }\n",
    "\n",
    "lineage_bday = estimate_lineage_bdays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strain_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    rate_mean = fit[\"mean\"][\"rate\"].mean(0)\n",
    "    rate_std = (fit[\"std\"][\"rate\"].mean(0) ** 2 + fit[\"mean\"][\"rate\"].std(0) ** 2).sqrt()\n",
    "    R_mean = rate_mean.exp()\n",
    "    lb, ub = dist.Normal(rate_mean, rate_std).icdf(torch.tensor([0.025, 0.975])[..., None])\n",
    "    RA = R_mean[lineage_id[\"A\"]].item()\n",
    "    R_RA = R_mean / RA\n",
    "    probs = fit[\"median\"][\"probs\"]\n",
    "    cases = torch.einsum(\"tps,tp->ts\", probs, weekly_cases)\n",
    "    cases_per_day = cases[-2] / mutrans.TIMESTEP\n",
    "    cases_total = cases.sum(0)\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"strain\", \"{:s}\"),\n",
    "        (\"R / R_A\", \"{:.6g}\"),\n",
    "        (\"95% ci lower\", \"{:.6g}\"),\n",
    "        (\"95% ci upper\", \"{:.6g}\"),\n",
    "        (\"confirmed cases / day\", \"{:.6g}\"),\n",
    "        (\"confirmed cases total\", \"{:.6g}\"),\n",
    "        (\"birthday\", \"{:s}\"),\n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(R_RA.sort(0, descending=True).indices.tolist()):\n",
    "            lineage = lineage_id_inv[i]\n",
    "            f.write(row.format(\n",
    "                rank + 1, lineage,\n",
    "                R_RA[i], lb[i], ub[i], cases_per_day[i], cases_total[i],\n",
    "                lineage_bday[pangolin.decompress(lineage)],\n",
    "            ))\n",
    "\n",
    "write_strain_table(best_fit, \"paper/strains.tsv\")\n",
    "pd.read_csv(\"paper/strains.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with deep mutational scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare with [(Starr et al. 2020)](https://www.sciencedirect.com/science/article/pii/S0092867420310035) who study S mutations affecting folding and ACE2 binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S0092867420310035-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = {f\"S:{m}\": float(e) for m, e in zip(df[\"mutation\"], df[\"expr_avg\"])}\n",
    "binding = {f\"S:{m}\": float(b) for m, b in zip(df[\"mutation\"], df[\"bind_avg\"])}\n",
    "print(sum(1 for m in mutations if m in folding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compare with [(Greaney et al. 2021)](https://www.sciencedirect.com/science/article/pii/S1931312820306247) who study antibody escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S1931312820306247-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape = {\n",
    "    f\"S:{w}{s}{m}\": float(e)\n",
    "    for w, s, m, e in zip(df[\"wildtype\"], df[\"site\"], df[\"mutation\"], df[\"mut_escape\"])\n",
    "}\n",
    "print(sum(1 for m in mutations if m in escape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "ms = [m for m in mutations if m in escape]\n",
    "y = best_fit[\"mean\"][\"rate_coef\"][[i for i, m in enumerate(mutations) if m in escape]].numpy()\n",
    "axes[0].set_ylabel(\"Δ log R\")\n",
    "for name, ax in zip([\"folding\", \"binding\", \"escape\"], axes):\n",
    "    scan = locals()[name]\n",
    "    x = torch.tensor([scan[m] for m in ms]).numpy()\n",
    "    # ax.scatter(x, y, alpha=0.5, lw=0)\n",
    "    for xm, ym, m in zip(x, y, ms):\n",
    "        ax.text(xm, ym, m[2:], fontsize=6,\n",
    "                verticalalignment=\"center\", horizontalalignment=\"center\")\n",
    "    ax.set_xlim(1.08 * x.min() - 0.08 * x.max(), 1.08 * x.max() - 0.08 * x.min())\n",
    "    ax.set_ylim(1.05 * y.min() - 0.05 * y.max(), 1.05 * y.max() - 0.05 * y.min())\n",
    "    ax.set_xlabel(f\"{name} (ρ = {correlation(x, y):0.2g})\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "axes[2].set_xscale(\"log\")\n",
    "axes[2].set_xlim(x.min() ** 1.08 / x.max() ** 0.08, x.max() ** 1.08 / x.min() ** 0.08)\n",
    "axes[1].set_title(f\"Comparison of {len(ms)} S gene mutations to deep scanning\")\n",
    "plt.subplots_adjust(wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say whether these correlations are meaningful, as they are dominated by a few outliers.\n",
    "\n",
    "Let's fit a linear model regressing transmissibility against theses deep scanning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "def fit_model(fit):\n",
    "    trans_data = fit[\"mean\"][\"rate_coef\"][[i for i, m in enumerate(mutations) if m in escape]]\n",
    "    folding_data = torch.tensor([folding[m] for m in ms])\n",
    "    binding_data = torch.tensor([binding[m] for m in ms])\n",
    "    escape_data = torch.tensor([escape[m] for m in ms])\n",
    "    \n",
    "    def model():\n",
    "        coef = pyro.sample(\"coef\", dist.Normal(0, 10).expand([5]).to_event(1))\n",
    "        t, f, b, e, be = coef.unbind(-1)\n",
    "        noise = pyro.sample(\"noise\", dist.LogNormal(0, 2))\n",
    "        with pyro.plate(\"data\", len(trans_data)):\n",
    "            pred = (\n",
    "                t + f * folding_data + b * binding_data + e * escape_data\n",
    "                + be * binding_data * escape_data\n",
    "            )\n",
    "            pyro.sample(\"trans\", dist.Normal(pred, noise), obs=trans_data)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    elbo = Trace_ELBO(num_particles=100, vectorize_particles=True)\n",
    "    svi = SVI(model, guide, Adam({\"lr\": 0.2}), elbo)\n",
    "    for step in range(201):\n",
    "        loss = svi.step()\n",
    "        if step % 20 == 0:\n",
    "            print(f\"step {step} loss = {loss:0.4g}\")\n",
    "    loc, scale = guide._loc_scale()\n",
    "    print(\"Model:\")\n",
    "    print(\"transmissibility = t + f folding + b binding + e escape + be binding escape\")\n",
    "    print(\"Learned coefficients:\")\n",
    "    for k, l, s in zip(\"t f b e be\".split(), loc.tolist(), scale.tolist()):\n",
    "        print(f\"{k} = {l:0.4g} +- {s:0.2f}\")\n",
    "        \n",
    "fit_model(best_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter([n for n in columns[\"virus_name\"] if \"-CDC-2-\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"USA\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"United King\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"North America \" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"Europe \" in n]).most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_fits = {k[-1]: v for k, v in fits.items() if k[-1]}\n",
    "for key in holdout_fits:\n",
    "    print(key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = [\n",
    "    \"only Europe\",\n",
    "    \"excluding Europe\",\n",
    "    # \"only North America\",\n",
    "    # \"excluding North America\",\n",
    "    # \"only the USA\",\n",
    "    # \"excluding the USA\",\n",
    "    # \"excluding the UK\",\n",
    "    # \"only the UK\",\n",
    "    # \"only CDC data\",\n",
    "    # \"only CDC NS3 data\",\n",
    "]\n",
    "holdout_fits = dict(zip(aliases, holdout_fits.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        return fit[\"mean\"][\"rate_coef\"]\n",
    "    mean1 = get_mean(fit1)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in [mean1] + means)\n",
    "    x1 = max(mean.max().item() for mean in [mean1] + means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(len(holdouts) * 3, 3), sharey=True)\n",
    "    fig.suptitle(\"Δ log R for {} mutations estimated from full versus subsets of data\"\n",
    "                 .format(len(fit1[\"mutations\"])))\n",
    "    for ax, (name, fit2), mean2 in zip(axes, holdouts.items(), means):\n",
    "        mutations = sorted(set(fit1[\"mutations\"]) & set(fit2[\"mutations\"]))\n",
    "        means = []\n",
    "        for fit, mean in ((fit1, mean1), (fit2, mean2)):\n",
    "            m_to_i = {m: i for i, m in enumerate(fit[\"mutations\"])}\n",
    "            idx = torch.tensor([m_to_i[m] for m in mutations])\n",
    "            means.append(mean[idx])\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 50, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 30, alpha=0.3, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(means[0], means[1])))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_mutation_agreements(best_fit, holdout_fits, [\"paper/mutation_agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        rate = fit[\"median\"][\"rate\"]\n",
    "        return (rate - rate[lineage_id[\"A\"]]).exp()\n",
    "    mean1 = get_mean(fit1)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in [mean1] + means)\n",
    "    x1 = max(mean.max().item() for mean in [mean1] + means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(len(holdouts) * 3, 3), sharey=True)\n",
    "    fig.suptitle(\"$R_{{lineage}} / R_A$ for {} lineages esimated from full versus subsets of data\"\n",
    "                 .format(len(lineage_id)))\n",
    "    for ax, name, mean2 in zip(axes, holdouts, means):\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(mean2.numpy(), mean1.numpy(), 50, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(mean2.numpy(), mean1.numpy(), 30, alpha=0.3, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(mean1, mean2)))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_strain_agreements(best_fit, holdout_fits, [\"paper/lineage_agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_subset_boxplot(fits, rankby=\"s\", top_k=20, filenames=()):\n",
    "    best_fit = next(iter(fits.values()))\n",
    "    if rankby == \"s\":\n",
    "        rankby = best_fit[\"mean\"][\"rate_coef\"] / best_fit[\"std\"][\"rate_coef\"]\n",
    "        title = f\"Top {top_k} most statistically significant mutations\"\n",
    "    elif rankby == \"t\":\n",
    "        rankby = best_fit[\"mean\"][\"rate_coef\"]\n",
    "        title = f\"Top {top_k} most transmissible mutations\"\n",
    "    else: raise ValueError(rankby)\n",
    "    top_indices = rankby.sort(0, descending=True).indices[:top_k]\n",
    "    top_mutations = [mutations[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"rate_coef\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"mean\"][\"rate_coef\"][top_indices]\n",
    "            std = fit[\"std\"][\"rate_coef\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean(0)\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "    \n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'pink', 'lightgreen']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 9})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               # labels=[x.replace(\":\", \":\\n\") for x in top_mutations],\n",
    "               labels=top_mutations, rotation=-90, fontsize=9)\n",
    "    plt.ylabel(\"Δ log R\")\n",
    "    plt.title(title)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "for name in [\"Europe\"]:\n",
    "    name_ = name.lower().replace(\" \", \"_\")\n",
    "    plot_mutation_subset_boxplot({\n",
    "        f\"World w/o {name}\": holdout_fits[f\"excluding {name}\"],\n",
    "        \"World\": best_fit,\n",
    "        f\"{name} only\": holdout_fits[f\"only {name}\"],\n",
    "    }, filenames=[f\"paper/mutation_{name_}_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_subset_boxplot(fits, top_k=20, filenames=()):\n",
    "    best_fit = next(iter(fits.values()))\n",
    "    top_indices = best_fit[\"mean\"][\"rate\"].sort(0, descending=True).indices[:top_k]\n",
    "    top_lineages = [lineage_id_inv[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"rate\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"median\"][\"rate\"][top_indices]\n",
    "            std = fit[\"std\"][\"rate\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        samples = samples - fit[\"median\"][\"rate\"][lineage_id[\"A\"]]\n",
    "        samples = samples.exp()\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean()\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'pink', 'lightgreen']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 10})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               labels=top_lineages, rotation=-90)\n",
    "    plt.ylabel(\"$R / R_A$\")\n",
    "    plt.title(f\"Top {top_k} most transmissible lineages\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "for name in [\"Europe\"]:\n",
    "    name_ = name.lower().replace(\" \", \"_\")\n",
    "    plot_strain_subset_boxplot({\n",
    "        f\"World w/o {name}\": holdout_fits[f\"excluding {name}\"],\n",
    "        \"World\": best_fit,\n",
    "        f\"{name} only\": holdout_fits[f\"only {name}\"],\n",
    "    }, filenames=[f\"paper/strain_{name_}_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
