{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for mutation-transmissibility paper\n",
    "\n",
    "This notebook generates plots for the [paper/](paper/) directory. This assumes you've alread run\n",
    "```sh\n",
    "make update        # ~30 minutes on CPU (mostly sequence alignment)\n",
    "python mutrans.py  # ~2 hours on GPU (mostly MCMC)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import logging\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyrocov import mutrans, pangolin, stats\n",
    "from pyrocov.stats import normal_log10bf\n",
    "\n",
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)\n",
    "torch.set_default_dtype(torch.double)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "matplotlib.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "# matplotlib.rcParams[\"axes.linewidth\"] = 0.5\n",
    "matplotlib.rcParams[\"lines.markeredgewidth\"]\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = [\n",
    "    # 'Helvetica Neue',\n",
    "    # 'Hiragino Sans',\n",
    "    # 'Heiti TC',\n",
    "    'Arial', 'Avenir', 'DejaVu Sans',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-6, 6, 201)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x, dist.Normal(0, 1).log_prob(x), 'b-', lw=1, label=\"Normal\", alpha=0.8)\n",
    "plt.plot(x, dist.Cauchy(0, 1).log_prob(x), 'g-', lw=1, label=\"Cauchy\", alpha=0.8)\n",
    "plt.plot(x, dist.Laplace(0, 1).log_prob(x), 'r-', lw=1, label=\"Laplace\", alpha=0.8)\n",
    "plt.plot(x, dist.SoftLaplace(0, 1).log_prob(x), 'w-', lw=4)\n",
    "plt.plot(x, dist.SoftLaplace(0, 1).log_prob(x), 'r--', lw=2, label=\"SoftLaplace\")\n",
    "plt.ylabel(\"log density\")\n",
    "plt.ylim(-6, -0.5)\n",
    "plt.xlim(-6, 6)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend(loc='lower center')\n",
    "plt.tight_layout()\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = mutrans.load_gisaid_data()\n",
    "dataset.update(mutrans.load_jhu_data(dataset))\n",
    "print(dataset.keys())\n",
    "locals().update(dataset)\n",
    "print(len(mutations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checking case count time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(weekly_cases, lw=1, alpha=0.5)\n",
    "plt.yscale(\"symlog\", linthresh=10)\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, len(weekly_cases) - 1)\n",
    "plt.xlabel(\"fortnight after 2019-12-01\")\n",
    "plt.ylabel(\"confirmed cases\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set(location_id)\n",
    "N_usa = sum(1 for k in locations if \"/ USA /\" in k)\n",
    "N_uk = sum(1 for k in locations if \"/ United Kingdom /\" in k)\n",
    "N_other = len(locations) - N_usa - N_uk\n",
    "print(N_usa, N_uk, N_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll account for epidemiological dynamics in the form of random drift on top of our logistic growth model. Since random drift is inversely proportional to the local number of infections, we'll need a new data source for the number of infections in each region. We'll use JHU's confirmed case counts time series as a proxy for the number of total infections in each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = torch.load(\"results/mutrans.pt\", map_location=\"cpu\")\n",
    "svi_fit = list(fits.values())[0]\n",
    "mcmc_fit = list(fits.values())[1]\n",
    "for key in fits:\n",
    "    print(key)\n",
    "print(\"SVI:\", svi_fit.keys())\n",
    "print(\"MCMC:\", mcmc_fit.keys())\n",
    "print(mcmc_fit[\"diagnostics\"].keys())\n",
    "print(mcmc_fit[\"diagnostics\"][\"rate_coef\"].keys())\n",
    "print(mcmc_fit[\"median\"].keys())\n",
    "print(len(svi_fit[\"mutations\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in fits.items():\n",
    "    median = value[\"median\"]\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(value[\"losses\"], lw=1)\n",
    "    plt.xlabel(\"learning step (duration = {:0.1f} minutes)\".format(value[\"walltime\"]/60))\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"{} (conc. = {:0.3g}, f.scale = {:0.3g})\".format(\n",
    "        key[0],\n",
    "        median[\"concentration\"].item(),\n",
    "        median[\"feature_scale\"].item(),\n",
    "    ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mcmc_fits = []\n",
    "for key, fit in fits.items():\n",
    "    if key[0] != \"mcmc\":\n",
    "        continue\n",
    "    max_tree_depth = key[3]\n",
    "    n_eff = fit[\"diagnostics\"][\"rate_coef\"][\"n_eff\"]\n",
    "    mcmc_fits.append((max_tree_depth, n_eff))\n",
    "fig, axes = plt.subplots(len(mcmc_fits), 1, sharex=True, figsize=(8, 3 + len(mcmc_fits)))\n",
    "if len(mcmc_fits) == 1:\n",
    "    axes = [axes]\n",
    "for (max_tree_depth, n_eff), ax in zip(mcmc_fits, axes):\n",
    "    if torch.isnan(n_eff).any():\n",
    "        print(\"ERROR n_eff is NAN\")\n",
    "        continue\n",
    "    base = 2 ** 0.2\n",
    "    bins = [base ** i for i in range(int(n_eff.log().min() / math.log(base)),\n",
    "                                     int(n_eff.log().max() / math.log(base)) + 2)]\n",
    "    ax.hist(n_eff.numpy(), bins=bins)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(f\"max tree depth = {max_tree_depth}\")\n",
    "axes[0].set_title(\"MCMC effective sample size of rate_coef\")\n",
    "axes[-1].set_xlabel(\"effective sample size\")\n",
    "plt.subplots_adjust(hspace=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.isnan(n_eff).any():\n",
    "    print(\"ERROR n_eff is NAN\")\n",
    "else:\n",
    "    sigma = mcmc_fit[\"mean\"][\"rate_coef\"] / mcmc_fit[\"std\"][\"rate_coef\"]\n",
    "    plt.scatter(sigma.numpy(), n_eff.numpy(), 20, lw=0, alpha=0.3)\n",
    "    plt.ylabel(\"effective sample size\")\n",
    "    plt.xlabel(\"statistical significance = |μ|/σ\")\n",
    "    plt.xscale(\"symlog\", linthresh=2)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Does N_eff depend on the significance metric?\")\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    svi_fit[\"mean\"][\"rate_coef\"].numpy(),\n",
    "    mcmc_fit[\"mean\"][\"rate_coef\"].numpy(),\n",
    "    10, lw=0, alpha=0.5\n",
    ")\n",
    "x0 = min(svi_fit[\"mean\"][\"rate_coef\"].min().item(),\n",
    "         mcmc_fit[\"mean\"][\"rate_coef\"].min().item())\n",
    "x1 = max(svi_fit[\"mean\"][\"rate_coef\"].max().item(),\n",
    "         mcmc_fit[\"mean\"][\"rate_coef\"].max().item())\n",
    "plt.plot([x0, x1], [x0, x1], 'k--', alpha=0.2, zorder=-100)\n",
    "plt.xscale(\"symlog\")\n",
    "plt.yscale(\"symlog\")\n",
    "plt.title(\"SVI versus MCMC: μ = effect size\")\n",
    "plt.xlabel(\"SVI estimate\")\n",
    "plt.ylabel(\"MCMC estimate\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_sigma = svi_fit[\"mean\"][\"rate_coef\"] / svi_fit[\"std\"][\"rate_coef\"]\n",
    "mcmc_sigma = mcmc_fit[\"mean\"][\"rate_coef\"] / mcmc_fit[\"std\"][\"rate_coef\"]\n",
    "plt.scatter(svi_sigma.numpy(), mcmc_sigma.numpy(), 10, lw=0, alpha=0.5)\n",
    "x0 = min(svi_sigma.min().item(), mcmc_sigma.min().item())\n",
    "x1 = max(svi_sigma.max().item(), mcmc_sigma.max().item())\n",
    "plt.plot([x0, x1], [x0, x1], 'k--', alpha=0.2, zorder=-100)\n",
    "plt.xscale(\"symlog\")\n",
    "plt.yscale(\"symlog\")\n",
    "plt.title(\"SVI versus MCMC: |μ|/σ = statistical significance\")\n",
    "plt.xlabel(\"SVI estimate\")\n",
    "plt.ylabel(\"MCMC estimate\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_coefficients(name, rate_coef):\n",
    "    xs, idx = rate_coef.sort(0)\n",
    "    assert len(idx) == len(mutations)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title(f\"{name} regression coefficients (mutations)\")\n",
    "    plt.plot(xs, 'k.', lw=0, markersize=1, zorder=10)\n",
    "    plt.axhline(0, color='black', lw=0.5, linestyle='--', alpha=0.5)\n",
    "    plt.xlabel(f\"rank among {len(xs)} mutations\")\n",
    "    plt.ylabel(\"Δ transmissibility\")  # TODO convert to Δ log R\n",
    "\n",
    "    I = len(idx)\n",
    "    y0 = float(xs.min())\n",
    "    y1 = float(xs.max())\n",
    "    N = 50\n",
    "    for i in range(N):\n",
    "        x = -I / 8\n",
    "        y = y0 + (y1 - y0) * i / (N - 1)\n",
    "        plt.plot([i, x], [xs[i], y], color='blue', lw=0.3)\n",
    "        plt.text(x, y, mutations[int(idx[i])] + \" \", fontsize=5, color='blue',\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"right\")\n",
    "    for i in range(I - N, I):\n",
    "        x = I + I / 8\n",
    "        y = y1 + (y0 - y1) * (I - i - 1) / (N - 1)\n",
    "        plt.plot([i, x], [xs[i], y], color='red', lw=0.3)\n",
    "        plt.text(x, y, \" \" + mutations[int(idx[i])], fontsize=5, color='red',\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    plt.ylim(y0 - (y1 - y0) / 40, y1 + (y1 - y0) / 40)\n",
    "    plt.xlim(-0.35 * I, 1.35 * I)\n",
    "    plt.xticks(())\n",
    "\n",
    "plot_coefficients(\"SVI\", svi_fit[\"median\"][\"rate_coef\"])\n",
    "plot_coefficients(\"MCMC\", mcmc_fit[\"median\"][\"rate_coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_decomposition(median, queries, num_parts=7, months_ahead=3):\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    fig, axes = plt.subplots(len(queries), figsize=(8, 1 + 1.2 * len(queries)), sharex=True)\n",
    "    for row, (place_query, ax) in enumerate(zip(queries, axes)):\n",
    "        names = [name for name, i in location_id.items() if place_query in name]\n",
    "        assert len(names) == 1, place_query\n",
    "        id_ = location_id[names[0]]\n",
    "        rate = median[\"rate\"]\n",
    "        # FIXME this ignores region population when aggregating:\n",
    "        init = median[\"init\"][id_]\n",
    "        assert init.shape == rate.shape\n",
    "        time = torch.linspace(0, months_ahead / 12.0, 100)\n",
    "        local_time = time + dataset[\"local_time\"][-1, id_]\n",
    "        portion = (init + rate * local_time[:, None]).softmax(-1)\n",
    "\n",
    "        # Aggregate into top + others.\n",
    "        best = portion.sum(0).sort(0, descending=True).indices\n",
    "        parts = {\"other\": None}\n",
    "        for i in range(num_parts - 1):\n",
    "            i = best[num_parts - i - 2].item()\n",
    "            parts[lineage_id_inv[i]] = portion[:, i].clone()\n",
    "            portion[:, i] = 0\n",
    "        parts[\"other\"] = portion.sum(-1)\n",
    "        months = time * 12\n",
    "\n",
    "        ax.stackplot(months, *parts.values(), labels=tuple(parts))\n",
    "        ax.set_xlim(months.min(), months.max())\n",
    "        ax.set_xticks((0, 1, 2, 3))\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks(())\n",
    "        ax.set_ylabel(names[0].split(\"/\")[-1].strip() if len(names) == 1 else place_query)\n",
    "        if row == len(axes) - 1:\n",
    "            ax.set_xlabel(\"Lineage prevalence forecast (months in future)\")\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles[::-1], labels[::-1], loc=\"lower right\", prop={\"size\": 6.5})\n",
    "    plt.subplots_adjust(hspace=0.02);\n",
    "\n",
    "plot_decomposition(mcmc_fit[\"median\"],\n",
    "                   [\"Mass\", \"Calif\", \"Texas\", \"Florida\", \"New York\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_baby_volcano(mean, std, linthresh=5):\n",
    "    xs = mean\n",
    "    ys = mean.abs() / std\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    p95 = dist.Normal(0, 1).icdf(torch.tensor(0.95)).item()\n",
    "    mask = (xs > 0) & (ys > p95)\n",
    "\n",
    "    plt.figure(figsize=(4, 4), dpi=300)\n",
    "    plt.title(f\"Δ transmissibility of {len(mutations)} mutations\")\n",
    "    plt.scatter(xs[~mask], ys[~mask], 5, color='#aaaaaa', lw=0)\n",
    "    plt.scatter(xs[mask], ys[mask], 5, color='black', lw=0)\n",
    "    plt.xlabel(\"effect size\")\n",
    "    plt.ylabel(\"statistical significance\")\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    # yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100] if y < y1]\n",
    "    # plt.yticks(yticks, list(map(str, yticks)))\n",
    "    plt.yticks(())\n",
    "    plt.xticks((-10, -5, 0, 5, 10))\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.axhline(p95, color='k', linestyle='--', alpha=0.3, zorder=-10)\n",
    "    plt.text(0.8 * x0 + 0.2 * x1, p95 * 0.85, \"95% probabililty\\nof correct sign\",\n",
    "             fontsize=10, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "             alpha=0.8, zorder=100)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_baby_volcano(mcmc_fit[\"mean\"][\"rate_coef\"], mcmc_fit[\"std\"][\"rate_coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_volcano(mean, std, filenames=(), linthresh=2, top_k=60):\n",
    "    ys = mean.abs() / std\n",
    "    xs = mean * 5.5 / 365.25\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    ys, idx = ys.sort(0, descending=True)\n",
    "    xs = xs[idx]\n",
    "    pos = (0 < xs) & (xs < math.inf)\n",
    "    neg = (-math.inf < xs) & (xs < 0)\n",
    "    ys_pos, ys_neg = ys[pos], ys[neg]\n",
    "    xs_pos, xs_neg = xs[pos], xs[neg]\n",
    "    idx_pos, idx_neg = idx[pos], idx[neg]\n",
    "    N = top_k\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\")\n",
    "    for mask in [pos, neg]:\n",
    "        xs_mask, ys_mask = xs[mask], ys[mask]\n",
    "        plt.plot(xs_mask[:N], ys_mask[:N], 'k.', lw=0, markersize=2, zorder=10)\n",
    "        plt.plot(xs_mask[N:], ys_mask[N:], 'k.', lw=0, markersize=2, zorder=10, color=\"#aaa\")\n",
    "    plt.xlabel(\"effect size (R / R_A = exp(μ))\")\n",
    "    xticks = [0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15]\n",
    "    plt.xticks(list(map(math.log, xticks)), list(map(str, xticks)))\n",
    "    plt.ylabel(\"statistical significance (|μ|/σ)\")\n",
    "    lpad = 0.33 if any(\",\" in mutations[i] for i in idx_neg[:N].tolist()) else 0.18\n",
    "    rpad = 0.33 if any(\",\" in mutations[i] for i in idx_pos[:N].tolist()) else 0.18\n",
    "    plt.xlim(x0 - (x1 - x0) * lpad, x1 + (x1 - x0) * rpad)\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100] if y < y1]\n",
    "    plt.yticks(yticks, list(map(str, yticks)))\n",
    "    p95 = dist.Normal(0, 1).icdf(torch.tensor(0.95)).item()\n",
    "    plt.plot([x0, x1], [p95, p95], 'k--', alpha=0.2)\n",
    "    plt.text(0.2 * x0 + 0.8 * x1, p95 * 0.95, \"95% probabililty\\nof correct sign(μ)\",\n",
    "             fontsize=7, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "             alpha=0.8, zorder=100)\n",
    "        \n",
    "    colors = {\"N\": \"blue\", \"S\": \"red\", \"M\": \"purple\", \"ORF3a\": \"darkgreen\"}\n",
    "    ax = plt.gca()\n",
    "    t = (ax.transScale + ax.transLimits).inverted()\n",
    "    for i in range(N):\n",
    "        x = x0\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        plt.plot([x, xs_neg[i]], [y, ys_neg[i]], color='gray', lw=0.2)\n",
    "        name = mutations[int(idx_neg[i])]\n",
    "        plt.text(x, y, name + \" \", color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"right\")\n",
    "    for i in range(N):\n",
    "        x = x1\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        name = mutations[int(idx_pos[i])]\n",
    "        plt.plot([x, xs_pos[i]], [y, ys_pos[i]], color='gray', lw=0.2)\n",
    "        plt.text(x, y, \" \" + name, color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.tight_layout()\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_volcano(mcmc_fit[\"mean\"][\"rate_coef\"], mcmc_fit[\"std\"][\"rate_coef\"], linthresh=5,\n",
    "             filenames=[\"paper/volcano.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrocov.sarscov2 import GENE_TO_POSITION, aa_mutation_to_position\n",
    "\n",
    "def plot_manhattan(mean, std, top_k=50, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    even = (gene_ids % 2 == 0) & (mean > 0)\n",
    "    odd = (gene_ids % 2 == 1) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    for mask, color in zip([even, odd], [\"darkblue\", \"darkred\"]):\n",
    "        plt.scatter(position[mask].numpy(), sigma[mask].numpy(), 8 * mean[mask].numpy(),\n",
    "                    color=color, alpha=0.5, lw=0)\n",
    "    special = {\"S\": [], \"N\": [], \"ORF3a\": []}  # Many hits, plot with lines\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene in special:\n",
    "            special[gene].append((y, x, name))\n",
    "            continue\n",
    "        plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                 verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    for special_ in special.values():\n",
    "        special_.sort(reverse=True)\n",
    "    y_bounds = {k: (min(y for (y, _, _) in v), max(y for (y, _, _) in v))\n",
    "                for k, v in special.items()}\n",
    "    for i, (y, x, name) in enumerate(special[\"S\"]):\n",
    "        lb, ub = y_bounds[\"S\"]\n",
    "        lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "        y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[\"S\"]) - 0.99)))\n",
    "        x_label = GENE_TO_POSITION[\"S\"][1] - 1000\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    for gene in [\"N\", \"ORF3a\"]:\n",
    "        for i, (y, x, name) in enumerate(special[gene]):\n",
    "            lb, ub = y_bounds[gene]\n",
    "            lb, ub = lb * 0.8, ub * 0.8 + y1 * 0.2\n",
    "            y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[gene]) - 0.99)))\n",
    "            x_label = GENE_TO_POSITION[gene][1] + 200\n",
    "            plt.text(x_label, y_label, name, fontsize=6,\n",
    "                     verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "            plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "        \n",
    "    start_end = list(GENE_TO_POSITION.values())\n",
    "    plt.xlim(start_end[0][0], start_end[-1][-1])\n",
    "    xticks = []\n",
    "    for i, (gene, (start, end)) in enumerate(GENE_TO_POSITION.items()):\n",
    "        if gene == \"ORF14\":\n",
    "            continue  # skip overlapping frame\n",
    "        plt.axvline(start, lw=0.1)\n",
    "        plt.axvline(end, lw=0.1)\n",
    "        xticks.extend([start, end])\n",
    "        plt.text((start + end) / 2, -y1 / 50, gene, rotation=-90,\n",
    "                 fontsize=6, verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "    plt.xticks(xticks, labels=())\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"μ / σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_manhattan(mcmc_fit[\"mean\"][\"rate_coef\"], mcmc_fit[\"std\"][\"rate_coef\"],\n",
    "               filenames=[\"paper/manhattan.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_upper_east_side(mean, std, top_k=120, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    mask = (gene_ids == gene_id[\"N\"]) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"Increased transmissibility of mutations within N gene\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    plt.scatter(position[mask].numpy(), sigma[mask].numpy(), 8 * mean[mask].numpy(),\n",
    "                color=\"darkblue\", alpha=0.5, lw=0)\n",
    "    special = []  # Many hits, plot with lines\n",
    "    z0 = 28800\n",
    "    z1 = 29000\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene != \"N\":\n",
    "            continue\n",
    "        if z0 < x < z1:\n",
    "            special.append((y, x, name))\n",
    "        else:\n",
    "            plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                     verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    special.sort(reverse=True)\n",
    "    lb = min(y for (y, _, _) in special)\n",
    "    ub = max(y for (y, _, _) in special)\n",
    "    lb, ub = lb * 0.5, ub * 0.5 + y1 * 0.5\n",
    "    for i, (y, x, name) in enumerate(special):\n",
    "        y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special) - 0.99)))\n",
    "        x_label = z1\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    start, end = GENE_TO_POSITION[\"N\"]\n",
    "    plt.xlim(start, end)\n",
    "    xticks = [start]\n",
    "    while xticks[-1] + 150 < end:\n",
    "        xticks.append(xticks[-1] + 150)\n",
    "    labels = [str((x - start) // 3) for x in xticks]\n",
    "    plt.xticks(xticks, labels)\n",
    "    plt.xlabel(\"amino acid position within N gene\")\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"μ / σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_upper_east_side(mcmc_fit[\"mean\"][\"rate_coef\"], mcmc_fit[\"std\"][\"rate_coef\"],\n",
    "                     filenames=[\"paper/upper_east_side.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_prevalence(filenames=()):\n",
    "    rate = mcmc_fit[\"median\"][\"rate\"]\n",
    "    rate = rate - rate[lineage_id[\"A\"]]\n",
    "    R = (rate * 5.5 / 365.25).exp()\n",
    "    init = mcmc_fit[\"median\"][\"init\"] + dataset[\"local_time\"][-2, :, None] * rate\n",
    "    init = init - init.logsumexp(-1, True)\n",
    "    cases = torch.einsum(\"ps,p->s\", init.exp(), weekly_cases[-2])\n",
    "    cases = cases / mutrans.TIMESTEP\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(R, cases, lw=0, alpha=0)\n",
    "    for name, i in lineage_id.items():\n",
    "        if cases[i] <= 1.1:\n",
    "            continue\n",
    "        plt.text(R[i], cases[i], name, fontsize=8, alpha=0.8,\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",)\n",
    "    plt.ylabel(\"confirmed cases / day\")\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xscale(\"log\")\n",
    "    plt.ylim(1, None)\n",
    "    plt.xlim(0.9, None)\n",
    "    xticks = (0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5)\n",
    "    plt.xticks(xticks, list(map(str, xticks)))\n",
    "    plt.xlabel(\"relative reproduction number $R_{strain} / R_A$\")\n",
    "    plt.tight_layout()\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "    \n",
    "plot_prevalence([\"paper/strain_prevalence.png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a table of top mutations and their stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_features = torch.zeros_like(features)\n",
    "for c, child in enumerate(lineage_id_inv):\n",
    "    child = pangolin.decompress(child)\n",
    "    parent = child\n",
    "    while True:\n",
    "        parent = \"A\" if parent == \"A\" else pangolin.get_parent(parent)\n",
    "        try:\n",
    "            p = lineage_id[pangolin.compress(parent)]\n",
    "            break\n",
    "        except KeyError:\n",
    "            continue\n",
    "    parent_features[c] = features[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emergences(i):\n",
    "    delta = features[:, i] - parent_features[:, i]\n",
    "    emerged = set((delta > 0.5).nonzero(as_tuple=True)[0].tolist())\n",
    "    emerged.add(delta.argmax().item())\n",
    "    result = []\n",
    "    for k in sorted(emerged):\n",
    "        name = lineage_id_inv[k]\n",
    "        longname = pangolin.decompress(name)\n",
    "        result.append(name if name == longname else f\"{name} ({longname})\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mutation_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    mean = fit[\"mean\"][\"rate_coef\"]\n",
    "    sigma = mean / fit[\"std\"][\"rate_coef\"].clamp(min=1e-8)\n",
    "    lb, ub = stats.confidence_interval(0.95, fit[\"samples\"][\"rate_coef\"])\n",
    "    R_RA = (mean * 5.5 / 365.25).exp()  # 5.5 is estimated generation time.\n",
    "    lineage_counts = weekly_strains.sum((0, 1))\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"mutation\", \"{:s}\"),\n",
    "        (\"mean/stddev\", \"{:0.6g}\"),\n",
    "        (\"mean\", \"{:0.6g}\"),\n",
    "        (\"95% ci lower\", \"{:0.6g}\"),\n",
    "        (\"95% ci upper\", \"{:0.6g}\"),\n",
    "        (\"R / R_A\", \"{:0.6g}\"),\n",
    "        (\"emerged in lineages\", \"{:s}\"),  \n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(sigma.sort(0, descending=True).indices.tolist()):\n",
    "            emerged = find_emergences(i)\n",
    "            f.write(row.format(\n",
    "                rank + 1, mutations[i],\n",
    "                sigma[i], mean[i], lb[i], ub[i], R_RA[i], \", \".join(emerged)\n",
    "            ))\n",
    "\n",
    "write_mutation_table(mcmc_fit, \"paper/mutations.tsv\")\n",
    "pd.read_csv(\"paper/mutations.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_bday = {}\n",
    "for lineage, day in zip(columns[\"lineage\"], columns[\"day\"]):\n",
    "    lineage = pangolin.decompress(lineage)\n",
    "    lineage_bday[lineage] = min(lineage_bday.get(lineage, math.inf), day)\n",
    "start_date = datetime.datetime.strptime(mutrans.START_DATE, \"%Y-%m-%d\")\n",
    "lineage_bday = {\n",
    "    lineage: (start_date + datetime.timedelta(days=day)).strftime(\"%Y-%m-%d\")\n",
    "    for lineage, day in lineage_bday.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strain_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    R_mean = (fit[\"mean\"][\"rate\"] * 5.5 / 365.25).exp()  # 5.5 is estimated generation time.\n",
    "    R_sample = (fit[\"samples\"][\"rate\"] * 5.5 / 365.25).exp()\n",
    "    RA = R_mean[lineage_id[\"A\"]]\n",
    "    R_RA = R_mean / RA\n",
    "    lb, ub = stats.confidence_interval(0.95, R_sample / RA)\n",
    "    logits = fit[\"mean\"][\"init\"] + dataset[\"local_time\"][..., None] * fit[\"mean\"][\"rate\"]\n",
    "    probs = (logits - logits.logsumexp(-1, True)).exp()\n",
    "    cases = torch.einsum(\"tps,tp->ts\", probs, weekly_cases)\n",
    "    cases_per_day = cases[-2] / mutrans.TIMESTEP\n",
    "    cases_total = cases.sum(0)\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"strain\", \"{:s}\"),\n",
    "        (\"R / R_A\", \"{:.6g}\"),\n",
    "        (\"95% ci lower\", \"{:.6g}\"),\n",
    "        (\"95% ci upper\", \"{:.6g}\"),\n",
    "        (\"confirmed cases / day\", \"{:.6g}\"),\n",
    "        (\"confirmed cases total\", \"{:.6g}\"),\n",
    "        (\"birthday\", \"{:s}\"),\n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(R_mean.sort(0, descending=True).indices.tolist()):\n",
    "            lineage = lineage_id_inv[i]\n",
    "            f.write(row.format(\n",
    "                rank + 1, lineage,\n",
    "                R_RA[i], lb[i], ub[i], cases_per_day[i], cases_total[i],\n",
    "                lineage_bday[pangolin.decompress(lineage)],\n",
    "            ))\n",
    "\n",
    "write_strain_table(mcmc_fit, \"paper/strains.tsv\")\n",
    "pd.read_csv(\"paper/strains.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with deep mutational scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare with [(Starr et al. 2020)](https://www.sciencedirect.com/science/article/pii/S0092867420310035) who study S mutations affecting folding and ACE2 binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S0092867420310035-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = {f\"S:{m}\": float(e) for m, e in zip(df[\"mutation\"], df[\"expr_avg\"])}\n",
    "binding = {f\"S:{m}\": float(b) for m, b in zip(df[\"mutation\"], df[\"bind_avg\"])}\n",
    "print(sum(1 for m in mutations if m in folding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compare with [(Greaney et al. 2021)](https://www.sciencedirect.com/science/article/pii/S1931312820306247) who study antibody escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S1931312820306247-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape = {\n",
    "    f\"S:{w}{s}{m}\": float(e)\n",
    "    for w, s, m, e in zip(df[\"wildtype\"], df[\"site\"], df[\"mutation\"], df[\"mut_escape\"])\n",
    "}\n",
    "print(sum(1 for m in mutations if m in escape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    y = (y - x.mean()) / y.std()\n",
    "    return (x * y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "ms = [m for m in mutations if m in escape]\n",
    "y = mcmc_fit[\"mean\"][\"rate_coef\"][[i for i, m in enumerate(mutations) if m in escape]].numpy()\n",
    "y = y * 5.5 / 365.25\n",
    "axes[0].set_ylabel(\"Δ log R\")\n",
    "for name, ax in zip([\"folding\", \"binding\", \"escape\"], axes):\n",
    "    scan = locals()[name]\n",
    "    x = torch.tensor([scan[m] for m in ms]).numpy()\n",
    "    # ax.scatter(x, y, alpha=0.5, lw=0)\n",
    "    for xm, ym, m in zip(x, y, ms):\n",
    "        ax.text(xm, ym, m[2:], fontsize=6,\n",
    "                verticalalignment=\"center\", horizontalalignment=\"center\")\n",
    "    ax.set_xlim(1.08 * x.min() - 0.08 * x.max(), 1.08 * x.max() - 0.08 * x.min())\n",
    "    ax.set_ylim(1.05 * y.min() - 0.05 * y.max(), 1.05 * y.max() - 0.05 * y.min())\n",
    "    ax.set_xlabel(f\"{name} (ρ = {correlation(x, y):0.2g})\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "axes[2].set_xscale(\"log\")\n",
    "axes[2].set_xlim(x.min() ** 1.08 / x.max() ** 0.08, x.max() ** 1.08 / x.min() ** 0.08)\n",
    "axes[1].set_title(f\"Comparison of {len(ms)} S gene mutations to deep scanning\")\n",
    "plt.subplots_adjust(wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say whether these correlations are meaningful, as they are dominated by a few outliers.\n",
    "\n",
    "Let's fit a linear model regressing transmissibility against theses deep scanning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "def fit_model(fit):\n",
    "    trans_data = fit[\"mean\"][\"rate_coef\"][[i for i, m in enumerate(mutations) if m in escape]]\n",
    "    folding_data = torch.tensor([folding[m] for m in ms])\n",
    "    binding_data = torch.tensor([binding[m] for m in ms])\n",
    "    escape_data = torch.tensor([escape[m] for m in ms])\n",
    "    \n",
    "    def model():\n",
    "        coef = pyro.sample(\"coef\", dist.Normal(0, 10).expand([5]).to_event(1))\n",
    "        t, f, b, e, be = coef.unbind(-1)\n",
    "        noise = pyro.sample(\"noise\", dist.LogNormal(0, 2))\n",
    "        with pyro.plate(\"data\", len(trans_data)):\n",
    "            pred = (\n",
    "                t + f * folding_data + b * binding_data + e * escape_data\n",
    "                + be * binding_data * escape_data\n",
    "            )\n",
    "            pyro.sample(\"trans\", dist.Normal(pred, noise), obs=trans_data)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    elbo = Trace_ELBO(num_particles=100, vectorize_particles=True)\n",
    "    svi = SVI(model, guide, Adam({\"lr\": 0.2}), elbo)\n",
    "    for step in range(201):\n",
    "        loss = svi.step()\n",
    "        if step % 20 == 0:\n",
    "            print(f\"step {step} loss = {loss:0.4g}\")\n",
    "    loc, scale = guide._loc_scale()\n",
    "    print(\"Model:\")\n",
    "    print(\"transmissibility = t + f folding + b binding + e escape + be binding escape\")\n",
    "    print(\"Learned coefficients:\")\n",
    "    for k, l, s in zip(\"t f b e be\".split(), loc.tolist(), scale.tolist()):\n",
    "        print(f\"{k} = {l:0.4g} +- {s:0.2f}\")\n",
    "        \n",
    "fit_model(mcmc_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter([n for n in columns[\"virus_name\"] if \"-CDC-2-\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"USA\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"United King\" in n]).most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_fits = {k[-1]: v for k, v in fits.items() if k[-1]}\n",
    "for key in holdout_fits:\n",
    "    print(key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = [\n",
    "    \"excluding the UK\",\n",
    "    \"excluding the USA\",\n",
    "    \"only the UK\",\n",
    "    \"only the USA\",\n",
    "    # \"only CDC data\",\n",
    "    # \"only CDC NS3 data\",\n",
    "]\n",
    "holdout_fits = dict(zip(aliases, holdout_fits.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        return fit[\"mean\"][\"rate_coef\"] * 5/5 / 365.25\n",
    "    mean1 = get_mean(fit1)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in [mean1] + means)\n",
    "    x1 = max(mean.max().item() for mean in [mean1] + means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(11, 3), sharey=True)\n",
    "    fig.suptitle(\"Δ log R for {} mutations estimated from full versus subsets of data\"\n",
    "                 .format(len(fit1[\"mutations\"])))\n",
    "    for ax, (name, fit2), mean2 in zip(axes, holdouts.items(), means):\n",
    "        mutations = sorted(set(fit1[\"mutations\"]) & set(fit2[\"mutations\"]))\n",
    "        means = []\n",
    "        for fit, mean in ((fit1, mean1), (fit2, mean2)):\n",
    "            m_to_i = {m: i for i, m in enumerate(fit[\"mutations\"])}\n",
    "            idx = torch.tensor([m_to_i[m] for m in mutations])\n",
    "            means.append(mean[idx])\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 60, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 30, alpha=0.4, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(means[0], means[1])))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_mutation_agreements(svi_fit, holdout_fits, [\"paper/agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        rate = fit[\"median\"][\"rate\"]\n",
    "        return ((rate - rate[lineage_id[\"A\"]]) * 5.5 / 365.25).exp()\n",
    "    mean1 = get_mean(fit1)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in [mean1] + means)\n",
    "    x1 = max(mean.max().item() for mean in [mean1] + means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(11, 3), sharey=True)\n",
    "    fig.suptitle(\"$R_{{lineage}} / R_A$ for {} lineages esimated from full versus subsets of data\"\n",
    "                 .format(len(lineage_id)))\n",
    "    for ax, name, mean2 in zip(axes, holdouts, means):\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(mean2.numpy(), mean1.numpy(), 60, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(mean2.numpy(), mean1.numpy(), 30, alpha=0.4, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(mean1, mean2)))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_strain_agreements(mcmc_fit, holdout_fits, [\"paper/agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_subset_boxplot(fits, rankby=\"s\", top_k=20, filenames=()):\n",
    "    best_fit = next(iter(fits.values()))\n",
    "    if rankby == \"s\":\n",
    "        rankby = best_fit[\"mean\"][\"rate_coef\"] / best_fit[\"std\"][\"rate_coef\"]\n",
    "        title = f\"Top {top_k} most statistically significant mutations\"\n",
    "    elif rankby == \"t\":\n",
    "        rankby = best_fit[\"mean\"][\"rate_coef\"]\n",
    "        title = f\"Top {top_k} most transmissible mutations\"\n",
    "    else: raise ValueError(rankby)\n",
    "    top_indices = rankby.sort(0, descending=True).indices[:top_k]\n",
    "    top_mutations = [mutations[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"rate_coef\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"mean\"][\"rate_coef\"][top_indices]\n",
    "            std = fit[\"std\"][\"rate_coef\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        samples = samples * 5.5 / 365.25\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean(0)\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "    \n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'lightgreen', 'pink']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 9})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               # labels=[x.replace(\":\", \":\\n\") for x in top_mutations],\n",
    "               labels=top_mutations, rotation=-90, fontsize=9)\n",
    "    plt.ylabel(\"Δ log R\")\n",
    "    plt.title(title)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_mutation_subset_boxplot({\n",
    "    \"World\": mcmc_fit,\n",
    "    # TODO infer these via MCMC\n",
    "    \"World w/o UK\": holdout_fits['excluding the UK'],\n",
    "    \"UK only\": holdout_fits['only the UK'],\n",
    "}, filenames=[\"paper/mutation_uk_boxplot.png\"])\n",
    "plot_mutation_subset_boxplot({\n",
    "    \"World\": mcmc_fit,\n",
    "    # TODO infer these via MCMC\n",
    "    \"World w/o USA\": holdout_fits['excluding the USA'],\n",
    "    \"USA only\": holdout_fits['only the USA'],\n",
    "}, filenames=[\"paper/mutation_usa_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_subset_boxplot(fits, top_k=20, filenames=()):\n",
    "    best_fit = next(iter(fits.values()))\n",
    "    top_indices = best_fit[\"mean\"][\"rate\"].sort(0, descending=True).indices[:top_k]\n",
    "    top_lineages = [lineage_id_inv[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"rate\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"median\"][\"rate\"][top_indices]\n",
    "            std = fit[\"std\"][\"rate\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        samples = samples - fit[\"median\"][\"rate\"][lineage_id[\"A\"]]\n",
    "        samples = (samples * 5.5 / 365.25).exp()\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean()\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'lightgreen', 'pink']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 10})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               labels=top_lineages, rotation=-90)\n",
    "    plt.ylabel(\"$R / R_A$\")\n",
    "    plt.title(f\"Top {top_k} most transmissible lineages\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_strain_subset_boxplot({\n",
    "    \"World\": mcmc_fit,\n",
    "    # TODO infer these via MCMC\n",
    "    \"World w/o UK\": holdout_fits['excluding the UK'],\n",
    "    \"UK only\": holdout_fits['only the UK'],\n",
    "}, filenames=[\"paper/strain_uk_boxplot.png\"])\n",
    "plot_strain_subset_boxplot({\n",
    "    \"World\": mcmc_fit,\n",
    "    # TODO infer these via MCMC\n",
    "    \"World w/o USA\": holdout_fits['excluding the USA'],\n",
    "    \"USA only\": holdout_fits['only the USA'],\n",
    "}, filenames=[\"paper/strain_usa_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
