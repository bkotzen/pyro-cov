{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for mutation-transmissibility paper\n",
    "\n",
    "This notebook generates plots for the paper/ directory. This assumes you've alread run\n",
    "```sh\n",
    "python mutrans.py  # ~2 hours on GPU (mostly MCMC)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import logging\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyrocov.geo import gisaid_to_jhu_location, parse_date, pd_to_torch, read_csv\n",
    "from pyrocov import mutrans, pangolin\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-6, 6, 201)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x, dist.Normal(0, 1).log_prob(x), 'b-', lw=1, label=\"Normal\", alpha=0.8)\n",
    "plt.plot(x, dist.Cauchy(0, 1).log_prob(x), 'g-', lw=1, label=\"Cauchy\", alpha=0.8)\n",
    "plt.plot(x, dist.Laplace(0, 1).log_prob(x), 'r-', lw=1, label=\"Laplace\", alpha=0.8)\n",
    "plt.plot(x, dist.SoftLaplace(0, 1).log_prob(x), 'w-', lw=4)\n",
    "plt.plot(x, dist.SoftLaplace(0, 1).log_prob(x), 'r--', lw=2, label=\"SoftLaplace\")\n",
    "plt.ylabel(\"log density\")\n",
    "plt.ylim(-6, -0.5)\n",
    "plt.xlim(-6, 6)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend(loc='lower center')\n",
    "plt.tight_layout()\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(0.5)\n",
    "    spine.set_alpha(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = mutrans.load_data()\n",
    "print(dataset.keys())\n",
    "locals().update(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set(location_id)\n",
    "N_usa = sum(1 for k in locations if \"/ USA /\" in k)\n",
    "N_uk = sum(1 for k in locations if \"/ United Kingdom /\" in k)\n",
    "N_other = len(locations) - N_usa - N_uk\n",
    "print(N_usa, N_uk, N_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = torch.load(\"results/mutrans.pt\", map_location=\"cpu\")\n",
    "svi_fit = list(fits.values())[0]\n",
    "mcmc_fit = list(fits.values())[1]\n",
    "for key in fits:\n",
    "    print(key)\n",
    "print(\"SVI:\", svi_fit.keys())\n",
    "print(\"MCMC:\", mcmc_fit.keys())\n",
    "print(mcmc_fit[\"diagnostics\"].keys())\n",
    "print(mcmc_fit[\"diagnostics\"][\"rate_coef\"].keys())\n",
    "print(mcmc_fit[\"median\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in fits.items():\n",
    "    median = value[\"median\"]\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(value[\"losses\"], lw=1)\n",
    "    plt.xlabel(\"learning step (duration = {:0.1f} minutes)\".format(value[\"walltime\"]/60))\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"{} (concentration = {:0.3g}, feature_scale = {:0.3g})\"\n",
    "              .format(key[0], median[\"concentration\"].item(), median[\"feature_scale\"].item()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_fits = []\n",
    "for key, fit in fits.items():\n",
    "    if key[0] != \"mcmc\":\n",
    "        continue\n",
    "    max_tree_depth = key[3]\n",
    "    n_eff = fit[\"diagnostics\"][\"rate_coef\"][\"n_eff\"]\n",
    "    mcmc_fits.append((max_tree_depth, n_eff))\n",
    "fig, axes = plt.subplots(len(mcmc_fits), 1, sharex=True, figsize=(8, 3 + len(mcmc_fits)))\n",
    "if len(mcmc_fits) == 1:\n",
    "    axes = [axes]\n",
    "for (max_tree_depth, n_eff), ax in zip(mcmc_fits, axes):\n",
    "    base = 2 ** 0.25\n",
    "    bins = [base ** i for i in range(int(n_eff.log().min() / math.log(base)),\n",
    "                                  int(n_eff.log().max() / math.log(base)) + 2)]\n",
    "    ax.hist(n_eff.numpy(), bins=bins)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(f\"mtd = {max_tree_depth}\")\n",
    "axes[0].set_title(\"MCMC effective sample size of rate_coef\")\n",
    "axes[-1].set_xlabel(\"effective sample size\")\n",
    "plt.subplots_adjust(hspace=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = mcmc_fit[\"mean\"] / mcmc_fit[\"std\"]\n",
    "plt.scatter(sigma.numpy(), n_eff.numpy(), 20, lw=0, alpha=0.3)\n",
    "plt.ylabel(\"effective sample size\")\n",
    "plt.xlabel(\"statistical significance = |μ|/σ\")\n",
    "plt.xscale(\"symlog\", linthresh=2)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Does N_eff depend on the significance metric?\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    svi_fit[\"mean\"].numpy(),\n",
    "    mcmc_fit[\"mean\"].numpy(),\n",
    "    10, lw=0, alpha=0.5\n",
    ")\n",
    "x0 = min(svi_fit[\"mean\"].min().item(), mcmc_fit[\"mean\"].min().item())\n",
    "x1 = max(svi_fit[\"mean\"].max().item(), mcmc_fit[\"mean\"].max().item())\n",
    "plt.plot([x0, x1], [x0, x1], 'k--', alpha=0.2, zorder=-100)\n",
    "plt.xscale(\"symlog\")\n",
    "plt.yscale(\"symlog\")\n",
    "plt.title(\"SVI versus MCMC: μ = effect size\")\n",
    "plt.xlabel(\"SVI estimate\")\n",
    "plt.ylabel(\"MCMC estimate\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_sigma = svi_fit[\"mean\"] / svi_fit[\"std\"]\n",
    "mcmc_sigma = mcmc_fit[\"mean\"] / mcmc_fit[\"std\"]\n",
    "plt.scatter(svi_sigma.numpy(), mcmc_sigma.numpy(), 10, lw=0, alpha=0.5)\n",
    "x0 = min(svi_sigma.min().item(), mcmc_sigma.min().item())\n",
    "x1 = max(svi_sigma.max().item(), mcmc_sigma.max().item())\n",
    "plt.plot([x0, x1], [x0, x1], 'k--', alpha=0.2, zorder=-100)\n",
    "plt.xscale(\"symlog\")\n",
    "plt.yscale(\"symlog\")\n",
    "plt.title(\"SVI versus MCMC: |μ|/σ = statistical significance\")\n",
    "plt.xlabel(\"SVI estimate\")\n",
    "plt.ylabel(\"MCMC estimate\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_coefficients(name, rate_coef):\n",
    "    xs, idx = rate_coef.sort(0)\n",
    "    assert len(idx) == len(mutations)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title(f\"{name} regression coefficients (mutations)\")\n",
    "    plt.plot(xs, 'k.', lw=0, markersize=1, zorder=10)\n",
    "    plt.axhline(0, color='black', lw=0.5, linestyle='--', alpha=0.5)\n",
    "    plt.xlabel(f\"rank among {len(xs)} mutations\")\n",
    "    plt.ylabel(\"increased transmissibility\")\n",
    "\n",
    "    I = len(idx)\n",
    "    y0 = float(xs.min())\n",
    "    y1 = float(xs.max())\n",
    "    N = 50\n",
    "    for i in range(N):\n",
    "        x = -I / 8\n",
    "        y = y0 + (y1 - y0) * i / (N - 1)\n",
    "        plt.plot([i, x], [xs[i], y], color='blue', lw=0.3)\n",
    "        plt.text(x, y, mutations[int(idx[i])] + \" \", fontsize=5, color='blue',\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"right\")\n",
    "    for i in range(I - N, I):\n",
    "        x = I + I / 8\n",
    "        y = y1 + (y0 - y1) * (I - i - 1) / (N - 1)\n",
    "        plt.plot([i, x], [xs[i], y], color='red', lw=0.3)\n",
    "        plt.text(x, y, \" \" + mutations[int(idx[i])], fontsize=5, color='red',\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    plt.ylim(y0 - (y1 - y0) / 40, y1 + (y1 - y0) / 40)\n",
    "    plt.xlim(-0.35 * I, 1.35 * I)\n",
    "    plt.xticks(())\n",
    "\n",
    "plot_coefficients(\"SVI\", svi_fit[\"median\"][\"rate_coef\"])\n",
    "plot_coefficients(\"MCMC\", mcmc_fit[\"median\"][\"rate_coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_decomposition(median, queries, num_parts=7, months_ahead=3):\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    fig, axes = plt.subplots(len(queries), figsize=(8, 1 + 1.2 * len(queries)), sharex=True)\n",
    "    for row, (place_query, ax) in enumerate(zip(queries, axes)):\n",
    "        names = [name for name, i in location_id.items() if place_query in name]\n",
    "        assert len(names) == 1, place_query\n",
    "        id_ = location_id[names[0]]\n",
    "        rate = median[\"rate\"]\n",
    "        # FIXME this ignores region population when aggregating:\n",
    "        init = median[\"init\"][id_]\n",
    "        assert init.shape == rate.shape\n",
    "        time = torch.linspace(0, months_ahead / 12.0, 100)\n",
    "        local_time = time + dataset[\"local_time\"][-1, id_]\n",
    "        portion = (init + rate * local_time[:, None]).softmax(-1)\n",
    "\n",
    "        # Aggregate into top + others.\n",
    "        best = portion.sum(0).sort(0, descending=True).indices\n",
    "        parts = {\"other\": None}\n",
    "        for i in range(num_parts - 1):\n",
    "            i = best[num_parts - i - 2].item()\n",
    "            parts[lineage_id_inv[i]] = portion[:, i].clone()\n",
    "            portion[:, i] = 0\n",
    "        parts[\"other\"] = portion.sum(-1)\n",
    "        months = time * 12\n",
    "\n",
    "        ax.stackplot(months, *parts.values(), labels=tuple(parts))\n",
    "        ax.set_xlim(months.min(), months.max())\n",
    "        ax.set_xticks((0, 1, 2, 3))\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks(())\n",
    "        ax.set_ylabel(names[0].split(\"/\")[-1].strip() if len(names) == 1 else place_query)\n",
    "        if row == len(axes) - 1:\n",
    "            ax.set_xlabel(\"Lineage prevalence forecast (months in future)\")\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles[::-1], labels[::-1], loc=\"lower right\", prop={\"size\": 6.5})\n",
    "    plt.subplots_adjust(hspace=0.02);\n",
    "\n",
    "plot_decomposition(mcmc_fit[\"median\"],\n",
    "                   [\"Mass\", \"Calif\", \"Texas\", \"Florida\", \"New York\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_baby_volcano(mean, std, linthresh=5):\n",
    "    xs = mean\n",
    "    ys = mean.abs() / std\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    p95 = dist.Normal(0, 1).icdf(torch.tensor(0.95)).item()\n",
    "    mask = (xs > 0) & (ys > p95)\n",
    "\n",
    "    plt.figure(figsize=(4, 4), dpi=300)\n",
    "    plt.title(f\"Δ transmissibility of {len(mutations)} mutations\")\n",
    "    plt.scatter(xs[~mask], ys[~mask], 5, color='#aaaaaa', lw=0)\n",
    "    plt.scatter(xs[mask], ys[mask], 5, color='black', lw=0)\n",
    "    plt.xlabel(\"effect size\")\n",
    "    plt.ylabel(\"statistical significance\")\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    # yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100] if y < y1]\n",
    "    # plt.yticks(yticks, list(map(str, yticks)))\n",
    "    plt.yticks(())\n",
    "    plt.xticks((-10, -5, 0, 5, 10))\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.axhline(p95, color='k', linestyle='--', alpha=0.3, zorder=-10)\n",
    "    plt.text(0.8 * x0 + 0.2 * x1, p95 * 0.85, \"95% probabililty\\nof correct sign\",\n",
    "             fontsize=10, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "             alpha=0.8, zorder=100)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_baby_volcano(mcmc_fit[\"mean\"], mcmc_fit[\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_volcano(mean, std, filenames=(), linthresh=10, top_k=60):\n",
    "    xs = mean\n",
    "    ys = mean.abs() / std\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    ys, idx = ys.sort(0, descending=True)\n",
    "    xs = xs[idx]\n",
    "    pos = (0 < xs) & (xs < math.inf)\n",
    "    neg = (-math.inf < xs) & (xs < 0)\n",
    "    ys_pos, ys_neg = ys[pos], ys[neg]\n",
    "    xs_pos, xs_neg = xs[pos], xs[neg]\n",
    "    idx_pos, idx_neg = idx[pos], idx[neg]\n",
    "    N = top_k\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\")\n",
    "    for mask in [pos, neg]:\n",
    "        xs_mask, ys_mask = xs[mask], ys[mask]\n",
    "        plt.plot(xs_mask[:N], ys_mask[:N], 'k.', lw=0, markersize=2, zorder=10)\n",
    "        plt.plot(xs_mask[N:], ys_mask[N:], 'k.', lw=0, markersize=2, zorder=10, color=\"#aaa\")\n",
    "    plt.xlabel(\"μ = effect size\")\n",
    "    plt.ylabel(\"|μ|/σ = statistical significance\")\n",
    "    plt.xlim(x0 - (x1 - x0) * 0.18, x1 + (x1 - x0) * 0.18)\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100] if y < y1]\n",
    "    plt.yticks(yticks, list(map(str, yticks)))\n",
    "    p95 = dist.Normal(0, 1).icdf(torch.tensor(0.95)).item()\n",
    "    plt.plot([x0, x1], [p95, p95], 'k--', alpha=0.2)\n",
    "    plt.text(0.2 * x0 + 0.8 * x1, p95 * 0.95, \"95% probabililty\\nof correct sign\",\n",
    "             fontsize=7, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "             alpha=0.8, zorder=100)\n",
    "        \n",
    "    colors = {\"N\": \"blue\", \"S\": \"red\", \"M\": \"purple\", \"ORF3a\": \"darkgreen\"}\n",
    "    ax = plt.gca()\n",
    "    t = (ax.transScale + ax.transLimits).inverted()\n",
    "    for i in range(N):\n",
    "        x = x0\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        plt.plot([x, xs_neg[i]], [y, ys_neg[i]], color='gray', lw=0.2)\n",
    "        name = mutations[int(idx_neg[i])]\n",
    "        plt.text(x, y, name + \" \", color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"right\")\n",
    "    for i in range(N):\n",
    "        x = x1\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        name = mutations[int(idx_pos[i])]\n",
    "        plt.plot([x, xs_pos[i]], [y, ys_pos[i]], color='gray', lw=0.2)\n",
    "        plt.text(x, y, \" \" + name, color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.tight_layout()\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_volcano(mcmc_fit[\"mean\"], mcmc_fit[\"std\"], linthresh=5,\n",
    "             filenames=[\"paper/volcano.png\", \"paper/volcano.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrocov.sarscov2 import GENE_TO_POSITION, aa_mutation_to_position\n",
    "\n",
    "def plot_manhattan(mean, std, top_k=50, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    even = (gene_ids % 2 == 0) & (mean > 0)\n",
    "    odd = (gene_ids % 2 == 1) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    for mask, color in zip([even, odd], [\"darkblue\", \"darkred\"]):\n",
    "        plt.scatter(position[mask].numpy(), sigma[mask].numpy(), 8 * mean[mask].numpy(),\n",
    "                    color=color, alpha=0.5, lw=0)\n",
    "    special = {\"S\": [], \"N\": [], \"ORF3a\": []}  # Many hits, plot with lines\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene in special:\n",
    "            special[gene].append((y, x, name))\n",
    "            continue\n",
    "        plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                 verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    for special_ in special.values():\n",
    "        special_.sort(reverse=True)\n",
    "    y_bounds = {k: (min(y for (y, _, _) in v), max(y for (y, _, _) in v))\n",
    "                for k, v in special.items()}\n",
    "    for i, (y, x, name) in enumerate(special[\"S\"]):\n",
    "        lb, ub = y_bounds[\"S\"]\n",
    "        lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "        y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[\"S\"]) - 0.99)))\n",
    "        x_label = GENE_TO_POSITION[\"S\"][1] - 1000\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    for gene in [\"N\", \"ORF3a\"]:\n",
    "        for i, (y, x, name) in enumerate(special[gene]):\n",
    "            lb, ub = y_bounds[gene]\n",
    "            lb, ub = lb * 0.8, ub * 0.8 + y1 * 0.2\n",
    "            y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[gene]) - 0.99)))\n",
    "            x_label = GENE_TO_POSITION[gene][1] + 200\n",
    "            plt.text(x_label, y_label, name, fontsize=6,\n",
    "                     verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "            plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "        \n",
    "    start_end = list(GENE_TO_POSITION.values())\n",
    "    plt.xlim(start_end[0][0], start_end[-1][-1])\n",
    "    xticks = []\n",
    "    for i, (gene, (start, end)) in enumerate(GENE_TO_POSITION.items()):\n",
    "        if gene == \"ORF14\":\n",
    "            continue  # skip overlapping frame\n",
    "        plt.axvline(start, lw=0.1)\n",
    "        plt.axvline(end, lw=0.1)\n",
    "        xticks.extend([start, end])\n",
    "        plt.text((start + end) / 2, -y1 / 50, gene, rotation=-90,\n",
    "                 fontsize=6, verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "    plt.xticks(xticks, labels=())\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"statistical significance = |μ|/σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_manhattan(mcmc_fit[\"mean\"], mcmc_fit[\"std\"],\n",
    "               filenames=[\"paper/manhattan.png\", \"paper/manhattan.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_upper_east_side(mean, std, top_k=120, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    mask = (gene_ids == gene_id[\"N\"]) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"Increased transmissibility of mutations within N gene\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    plt.scatter(position[mask].numpy(), sigma[mask].numpy(), 8 * mean[mask].numpy(),\n",
    "                color=\"darkblue\", alpha=0.5, lw=0)\n",
    "    special = []  # Many hits, plot with lines\n",
    "    z0 = 28800\n",
    "    z1 = 29000\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene != \"N\":\n",
    "            continue\n",
    "        if z0 < x < z1:\n",
    "            special.append((y, x, name))\n",
    "        else:\n",
    "            plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                     verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    special.sort(reverse=True)\n",
    "    lb = min(y for (y, _, _) in special)\n",
    "    ub = max(y for (y, _, _) in special)\n",
    "    lb, ub = lb * 0.5, ub * 0.5 + y1 * 0.5\n",
    "    for i, (y, x, name) in enumerate(special):\n",
    "        y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special) - 0.99)))\n",
    "        x_label = z1\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    start, end = GENE_TO_POSITION[\"N\"]\n",
    "    plt.xlim(start, end)\n",
    "    xticks = [start]\n",
    "    while xticks[-1] + 150 < end:\n",
    "        xticks.append(xticks[-1] + 150)\n",
    "    labels = [str((x - start) // 3) for x in xticks]\n",
    "    plt.xticks(xticks, labels)\n",
    "    plt.xlabel(\"amino acid position within N gene\")\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"statistical significance = |μ|/σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_upper_east_side(mcmc_fit[\"mean\"], mcmc_fit[\"std\"],\n",
    "                     filenames=[\"paper/upper_east_side.png\", \"paper/upper_east_side.pdf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a table of top mutations and their stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_features = torch.zeros_like(features)\n",
    "for c, child in enumerate(lineage_id_inv):\n",
    "    child = pangolin.decompress(child)\n",
    "    parent = child\n",
    "    while True:\n",
    "        parent = \"A\" if parent == \"A\" else pangolin.get_parent(parent)\n",
    "        try:\n",
    "            p = lineage_id[pangolin.compress(parent)]\n",
    "            break\n",
    "        except KeyError:\n",
    "            continue\n",
    "    parent_features[c] = features[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emergences(i):\n",
    "    delta = features[:, i] - parent_features[:, i]\n",
    "    emerged = set((delta > 0.5).nonzero(as_tuple=True)[0].tolist())\n",
    "    emerged.add(delta.argmax().item())\n",
    "    result = []\n",
    "    for k in sorted(emerged):\n",
    "        name = lineage_id_inv[k]\n",
    "        longname = pangolin.decompress(name)\n",
    "        result.append(name if name == longname else f\"{name} ({longname})\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mutation_table(mean, std, filename=\"paper/top_mutations.md\", top_k=200):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    lineage_counts = weekly_strains.sum((0, 1))\n",
    "    with open(filename, \"wt\") as md, open(filename.replace(\".md\", \".tsv\"), \"wt\") as tsv:\n",
    "        md.write(\"This file was automatically generated by mutation_stochatic_model.ipynb\\n\")\n",
    "        md.write(\"\\n\")\n",
    "        md.write(\"| mutation | mean/stddev | mean | emerged in lineages |\\n\")\n",
    "        md.write(\"| -------- | ----------- | ---- | ------------------- |\\n\")\n",
    "        tsv.write(\"mutation\\tmean/stddev\\tmean\\temerged in lineages\\n\")\n",
    "        for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "            emerged = find_emergences(i)\n",
    "            md.write(\"| {} | {:0.3g} | {:0.3g} | {} |\\n\".format(\n",
    "                mutations[i], sigma[i], mean[i], \", \".join(emerged)\n",
    "            ))\n",
    "            tsv.write(\"{}\\t{:0.6g}\\t{:0.6g}\\t{}\\n\".format(\n",
    "                mutations[i], sigma[i], mean[i], \", \".join(emerged)\n",
    "            ))\n",
    "\n",
    "write_mutation_table(mcmc_fit[\"mean\"], mcmc_fit[\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strain_table(mean, filename=\"paper/top_strains.md\", top_k=1000):\n",
    "    rate = mean.type_as(features) @ features.T * (12 / 365.25 * 14)\n",
    "    num_samples = weekly_strains.sum(0).long()\n",
    "    global_samples = num_samples.sum(0)\n",
    "    us_samples = sum(num_samples[i] for name, i in location_id.items() if \" USA \" in name)\n",
    "    ma_samples = sum(num_samples[i] for name, i in location_id.items() if \" Mass\" in name)\n",
    "    lineages = [None] * len(lineage_id)\n",
    "    for lineage, i in lineage_id.items():\n",
    "        lineages[i] = lineage\n",
    "    with open(filename, \"wt\") as md, open(filename.replace(\".md\", \".tsv\"), \"wt\") as tsv:\n",
    "        md.write(\"This file was automatically generated by mutation_stochatic_model.ipynb\\n\")\n",
    "        md.write(\"\\n\")\n",
    "        md.write(\"| strain | log growth rate | global samples | US samples | MA samples |\\n\")\n",
    "        md.write(\"| ------ | --------------- | -------------- | ---------- | ---------- |\\n\")\n",
    "        tsv.write(\"rank\\tstrain\\tlog growth rate\\tnumber of samples\\n\")\n",
    "        for i in rate.sort(0, descending=True).indices[:top_k].tolist():\n",
    "            emerged = find_emergences(i)\n",
    "            md.write(\"| {} | {:0.4g} | {:d} | {:d} | {:d}\\n\".format(\n",
    "                lineages[i], rate[i], global_samples[i], us_samples[i], ma_samples[i]\n",
    "            ))\n",
    "            tsv.write(\"{}\\t{:0.6g}\\t{:d}\\n\".format(\n",
    "                lineages[i], rate[i], global_samples[i], us_samples[i], ma_samples[i]\n",
    "            ))\n",
    "\n",
    "write_strain_table(mcmc_fit[\"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with deep mutational scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare with [(Starr et al. 2020)](https://www.sciencedirect.com/science/article/pii/S0092867420310035) who study S mutations affecting folding and ACE2 binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S0092867420310035-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = {f\"S:{m}\": float(e) for m, e in zip(df[\"mutation\"], df[\"expr_avg\"])}\n",
    "binding = {f\"S:{m}\": float(b) for m, b in zip(df[\"mutation\"], df[\"bind_avg\"])}\n",
    "print(sum(1 for m in mutations if m in folding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compare with [(Greaney et al. 2021)](https://www.sciencedirect.com/science/article/pii/S1931312820306247) who study antibody escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S1931312820306247-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape = {\n",
    "    f\"S:{w}{s}{m}\": float(e)\n",
    "    for w, s, m, e in zip(df[\"wildtype\"], df[\"site\"], df[\"mutation\"], df[\"mut_escape\"])\n",
    "}\n",
    "print(sum(1 for m in mutations if m in escape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    x = x / x.std()\n",
    "    y = y / y.std()\n",
    "    return (x * y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "ms = [m for m in mutations if m in escape]\n",
    "y = mcmc_fit[\"mean\"][[i for i, m in enumerate(mutations) if m in escape]].numpy()\n",
    "axes[0].set_ylabel(\"Δ transmissibility\")\n",
    "for name, ax in zip([\"folding\", \"binding\", \"escape\"], axes):\n",
    "    scan = locals()[name]\n",
    "    x = torch.tensor([scan[m] for m in ms]).numpy()\n",
    "    # ax.scatter(x, y, alpha=0.5, lw=0)\n",
    "    for xm, ym, m in zip(x, y, ms):\n",
    "        ax.text(xm, ym, m[2:], fontsize=6,\n",
    "                verticalalignment=\"center\", horizontalalignment=\"center\")\n",
    "    ax.set_xlim(1.08 * x.min() - 0.08 * x.max(), 1.08 * x.max() - 0.08 * x.min())\n",
    "    ax.set_ylim(1.05 * y.min() - 0.05 * y.max(), 1.05 * y.max() - 0.05 * y.min())\n",
    "    ax.set_xlabel(f\"{name} (ρ = {correlation(x, y):0.3g})\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "axes[2].set_xscale(\"log\")\n",
    "axes[2].set_xlim(x.min() ** 1.08 / x.max() ** 0.08, x.max() ** 1.08 / x.min() ** 0.08)\n",
    "axes[1].set_title(f\"Comparison of {len(ms)} S gene mutations to deep scanning\")\n",
    "plt.subplots_adjust(wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say whether these correlations are meaningful, as they are dominated by a few outliers.\n",
    "\n",
    "Let's fit a linear model regressing transmissibility against theses deep scanning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "def fit_model():\n",
    "    trans_data = mcmc_fit[\"mean\"][[i for i, m in enumerate(mutations) if m in escape]]\n",
    "    folding_data = torch.tensor([folding[m] for m in ms])\n",
    "    binding_data = torch.tensor([binding[m] for m in ms])\n",
    "    escape_data = torch.tensor([escape[m] for m in ms])\n",
    "    \n",
    "    def model():\n",
    "        coef = pyro.sample(\"coef\", dist.Normal(0, 10).expand([5]).to_event(1))\n",
    "        t, f, b, e, be = coef.unbind(-1)\n",
    "        noise = pyro.sample(\"noise\", dist.LogNormal(0, 2))\n",
    "        with pyro.plate(\"data\", len(trans_data)):\n",
    "            pred = (\n",
    "                t + f * folding_data + b * binding_data + e * escape_data\n",
    "                + be * binding_data * escape_data\n",
    "            )\n",
    "            pyro.sample(\"trans\", dist.Normal(pred, noise), obs=trans_data)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    elbo = Trace_ELBO(num_particles=100, vectorize_particles=True)\n",
    "    svi = SVI(model, guide, Adam({\"lr\": 0.2}), elbo)\n",
    "    for step in range(201):\n",
    "        loss = svi.step()\n",
    "        if step % 20 == 0:\n",
    "            print(f\"step {step} loss = {loss:0.4g}\")\n",
    "    loc, scale = guide._loc_scale()\n",
    "    print(\"Model:\")\n",
    "    print(\"transmissibility = t + f folding + b binding + e escape + be binding escape\")\n",
    "    print(\"Learned coefficients:\")\n",
    "    for k, l, s in zip(\"t f b e be\".split(), loc.tolist(), scale.tolist()):\n",
    "        print(f\"{k} = {l:0.4g} +- {s:0.2f}\")\n",
    "        \n",
    "fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter([n for n in columns[\"virus_name\"] if \"-CDC-2-\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"USA\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"United King\" in n]).most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_fits = {k[-1]: v for k, v in fits.items() if k[-1]}\n",
    "for key in holdout_fits:\n",
    "    print(key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = [\n",
    "    \"excluding the UK\",\n",
    "    \"excluding the USA\",\n",
    "    \"only the UK\",\n",
    "    \"only the USA\",\n",
    "    \"only CDC data\",\n",
    "    \"only CDC NS3 data\",\n",
    "]\n",
    "holdout_fits = dict(zip(aliases, holdout_fits.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_agreements(fit1, holdouts, filenames=()):\n",
    "    x0 = min(f[\"mean\"].min().item() for f in [fit1] + list(holdouts.values()))\n",
    "    x1 = max(f[\"mean\"].max().item() for f in [fit1] + list(holdouts.values()))\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(11, 2), sharey=True)\n",
    "    fig.suptitle(\"Agreement of mean estimates between full versus subsets of data\")\n",
    "    for ax, (name, fit2) in zip(axes, holdouts.items()):\n",
    "        mutations = sorted(set(fit1[\"mutations\"]) & set(fit2[\"mutations\"]))\n",
    "        means = []\n",
    "        for fit in (fit1, fit2):\n",
    "            m_to_i = {m: i for i, m in enumerate(fit[\"mutations\"])}\n",
    "            idx = torch.tensor([m_to_i[m] for m in mutations])\n",
    "            means.append(fit[\"mean\"][idx])\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 30, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 15, alpha=0.5, lw=0)\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(means[0], means[1])))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_mean_agreements(svi_fit, holdout_fits,\n",
    "                     filenames=[\"paper/agreement.png\", \"paper/agreement.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
