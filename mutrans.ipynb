{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for mutation-transmissibility paper\n",
    "\n",
    "This notebook generates plots for the [paper/](paper/) directory. This assumes you've alread run\n",
    "```sh\n",
    "make update        # ~30 minutes on CPU (mostly sequence alignment)\n",
    "python mutrans.py  # ~2 hours on GPU (mostly MCMC)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import logging\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyrocov import mutrans, pangolin, stats\n",
    "from pyrocov.stats import normal_log10bf\n",
    "\n",
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)\n",
    "torch.set_default_dtype(torch.double)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "matplotlib.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "# matplotlib.rcParams[\"axes.linewidth\"] = 0.5\n",
    "matplotlib.rcParams[\"lines.markeredgewidth\"]\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'Avenir', 'DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    y = (y - x.mean()) / y.std()\n",
    "    return (x * y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     3048 Loading data\n",
      "     4044 Training on 1459282 rows with columns:\n",
      "     4045 lineage, virus_name, accession_id, collection_date, location, add_location, day\n",
      "     6256 Partitioning the following countries into subregions: Australia, Belgium, Brazil, Canada, Denmark, France, Germany, India, Italy, Lithuania, Netherlands, Norway, Poland, Slovenia, South Africa, Spain, Sweden, Switzerland, USA, United Kingdom\n",
      "     6308 Loaded 1275 x 2257 feature matrix\n",
      "    21386 WARNING skipping unsampled lineage B.1.616\n",
      "    21765 WARNING skipping unsampled lineage AT.1\n",
      "    22483 WARNING skipping unsampled lineage B.1.617\n",
      "    24542 Keeping 1459229/1459282 rows (dropped 53)\n",
      "    24699 Keeping 1214/1782 regions\n",
      "    25702 Loaded 476 x 3617 daily case data, totaling 192469680.0\n",
      "    25703 Joining GISAID and JHU region codes\n",
      "    25965 Matching 1214 GISAID regions to 3617 JHU fuzzy regions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['location_id', 'mutations', 'weekly_strains', 'features', 'feature_order', 'feature_order_max', 'lineage_id', 'lineage_id_inv', 'local_time', 'daily_cases', 'weekly_cases'])\n",
      "2257\n",
      "CPU times: user 24 s, sys: 1.71 s, total: 25.7 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = mutrans.load_gisaid_data()\n",
    "dataset.update(mutrans.load_jhu_data(dataset))\n",
    "print(dataset.keys())\n",
    "locals().update(dataset)\n",
    "print(len(mutations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 x 1214 x 1275 = 116088750\n"
     ]
    }
   ],
   "source": [
    "print(\"{} x {} x {} = {}\".format(*weekly_strains.shape, weekly_strains.shape.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 1459282 samples\n"
     ]
    }
   ],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "print(\"Loaded data from {} samples\".format(len(columns[\"lineage\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checking case count time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(weekly_cases, lw=1, alpha=0.5)\n",
    "plt.yscale(\"symlog\", linthresh=10)\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, len(weekly_cases) - 1)\n",
    "plt.xlabel(\"fortnight after 2019-12-01\")\n",
    "plt.ylabel(\"confirmed cases\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set(location_id)\n",
    "N_usa = sum(1 for k in locations if \"/ USA /\" in k)\n",
    "N_uk = sum(1 for k in locations if \"/ United Kingdom /\" in k)\n",
    "N_other = len(locations) - N_usa - N_uk\n",
    "print(N_usa, N_uk, N_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll account for epidemiological dynamics in the form of random drift on top of our logistic growth model. Since random drift is inversely proportional to the local number of infections, we'll need a new data source for the number of infections in each region. We'll use JHU's confirmed case counts time series as a proxy for the number of total infections in each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = torch.load(\"results/mutrans.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in fits:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_fit = list(fits.values())[0]\n",
    "best_fit = svi_fit\n",
    "print(\"SVI:\", svi_fit.keys())\n",
    "mcmc_fits = [v for k, v in fits.items() if k[0] == \"mcmc\"]\n",
    "if mcmc_fits:\n",
    "    mcmc_fit, = [v for k, v in fits.items() if k[:2] == (\"mcmc\", \"mvn_delta_dependent\")\n",
    "                 if k[-1] == ()]\n",
    "    best_fit = mcmc_fit\n",
    "    print(\"MCMC:\", mcmc_fit.keys())\n",
    "    print(mcmc_fit[\"diagnostics\"].keys())\n",
    "    print(mcmc_fit[\"diagnostics\"][\"rate_coef_aux\"].keys())\n",
    "    print(mcmc_fit[\"median\"].keys())\n",
    "    print(len(svi_fit[\"mutations\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale `rate_coef` by 1/100 in all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALREADY_SCALED = set()\n",
    "\n",
    "def scale_tensors(x, name=\"rate_coef\", scale=0.01, prefix=\"\"):\n",
    "    if id(x) in ALREADY_SCALED:\n",
    "        return\n",
    "    if isinstance(x, dict):\n",
    "        for k, v in list(x.items()):\n",
    "            if k == name:\n",
    "                print(f\"{prefix}.{k}\")\n",
    "                x[k] = v * scale\n",
    "            elif k == \"diagnostics\":\n",
    "                continue\n",
    "            else:\n",
    "                scale_tensors(v, name, scale, f\"{prefix}.{k}\")\n",
    "    ALREADY_SCALED.add(id(x))\n",
    "                \n",
    "scale_tensors(fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assess model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_nonzero = int(torch.count_nonzero(weekly_strains))\n",
    "for key, value in fits.items():\n",
    "    median = value[\"median\"]\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(value[\"losses\"], lw=1)\n",
    "    plt.xlabel(\"learning step (duration = {:0.1f} minutes)\".format(value[\"walltime\"]/60))\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"{} (conc. = {:0.3g}, f.scale = {:0.3g}, loss = {:0.4g})\\n{}\".format(\n",
    "        key[0] + \"_\" + key[1] if key[0] == \"mcmc\" else key[0],\n",
    "        median[\"concentration\"].item(),\n",
    "        median[\"feature_scale\"].item(),\n",
    "        np.median(value[\"losses\"][-201:]) / num_nonzero,\n",
    "        key[-1],\n",
    "    ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mcmc_fits = []\n",
    "for key, fit in fits.items():\n",
    "    if key[0] != \"mcmc\":\n",
    "        continue\n",
    "    d = fit[\"diagnostics\"]\n",
    "    n_eff = d.get(\"rate_coef\", d.get(\"rate_coef_aux\"))[\"n_eff\"]\n",
    "    mcmc_fits.append((key[1], n_eff, fit))\n",
    "if mcmc_fits:\n",
    "    mcmc_fits.sort(key=lambda x: x[-1][\"walltime\"])\n",
    "    fig, axes = plt.subplots(len(mcmc_fits), 1, sharex=True, figsize=(8, 3 + len(mcmc_fits)))\n",
    "    if len(mcmc_fits) == 1:\n",
    "        axes = [axes]\n",
    "    for (config, n_eff, fit), ax in zip(mcmc_fits, axes):\n",
    "        walltime = fit[\"walltime\"]\n",
    "        feature_scale = float(fit[\"median\"][\"feature_scale\"])\n",
    "        concentration = float(fit[\"median\"][\"concentration\"])\n",
    "        if torch.isnan(n_eff).any():\n",
    "            print(\"ERROR n_eff is NAN\")\n",
    "            continue\n",
    "        base = 2 ** 0.2\n",
    "        bins = [base ** i for i in range(int(n_eff.log().min() / math.log(base)),\n",
    "                                         int(n_eff.log().max() / math.log(base)) + 2)]\n",
    "        ax.hist(n_eff.numpy(), bins=bins)\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.text(0.03, 0.5,\n",
    "                \"{}\\nconc. = {:0.3g}\\nfeat.scale = {:0.3g}\\n{:0.1f} minutes\".format(\n",
    "                    config, concentration, feature_scale, walltime / 60.0\n",
    "                ),\n",
    "                transform=ax.transAxes, verticalalignment=\"center\")\n",
    "    axes[0].set_title(\"MCMC effective sample size of rate_coef\")\n",
    "    axes[-1].set_xlabel(\"effective sample size\")\n",
    "    plt.subplots_adjust(hspace=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_fits = []\n",
    "for key, fit in fits.items():\n",
    "    if key[0] != \"mcmc\":\n",
    "        continue\n",
    "    d = fit[\"diagnostics\"]\n",
    "    r_hat = d.get(\"rate_coef\", d.get(\"rate_coef_aux\"))[\"r_hat\"]\n",
    "    mcmc_fits.append((key[1], r_hat, fit[\"walltime\"]))\n",
    "if mcmc_fits:\n",
    "    mcmc_fits.sort(key=lambda x: x[-1])\n",
    "    fig, axes = plt.subplots(len(mcmc_fits), 1, sharex=True, figsize=(8, 3 + len(mcmc_fits)))\n",
    "    if len(mcmc_fits) == 1:\n",
    "        axes = [axes]\n",
    "    for (config, r_hat, walltime), ax in zip(mcmc_fits, axes):\n",
    "        if torch.isnan(r_hat).any():\n",
    "            print(\"ERROR r_hat is NAN\")\n",
    "            continue\n",
    "        ax.hist(r_hat.numpy())\n",
    "        ax.text(0.03, 0.9, \"{}\\n{:0.1f} minutes\".format(config, walltime / 60.0),\n",
    "                transform=ax.transAxes, verticalalignment=\"top\")\n",
    "    axes[0].set_title(\"MCMC r_hat of rate_coef\")\n",
    "    axes[-1].set_xlabel(\"r_hat\")\n",
    "    plt.subplots_adjust(hspace=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svi_mcmc_mean():\n",
    "    x0 = svi_fit[\"mean\"][\"rate_coef\"].min().item()\n",
    "    x1 = svi_fit[\"mean\"][\"rate_coef\"].max().item()\n",
    "    plt.plot([x0, x1], [x0, x1], 'k--', alpha=0.2, zorder=-100)\n",
    "    for key, fit in fits.items():\n",
    "        if key[0] != \"mcmc\" or key[-1]:\n",
    "            continue\n",
    "        plt.scatter(\n",
    "            svi_fit[\"mean\"][\"rate_coef\"].numpy(),\n",
    "            fit[\"mean\"][\"rate_coef\"].numpy(),\n",
    "            10, lw=0, alpha=0.5, label=key[1]\n",
    "        )\n",
    "    plt.xscale(\"symlog\")\n",
    "    plt.yscale(\"symlog\")\n",
    "    plt.title(\"SVI versus MCMC: μ = effect size\")\n",
    "    plt.xlabel(\"SVI estimate\")\n",
    "    plt.ylabel(\"MCMC estimate\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "if mcmc_fits:\n",
    "    plot_svi_mcmc_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svi_mcmc_sigma():\n",
    "    svi_sigma = svi_fit[\"mean\"][\"rate_coef\"] / svi_fit[\"std\"][\"rate_coef\"]\n",
    "    x0 = svi_sigma.min().item()\n",
    "    x1 = svi_sigma.max().item()\n",
    "    plt.plot([x0, x1], [x0, x1], 'k--', alpha=0.2)\n",
    "    for key, fit in fits.items():\n",
    "        if key[0] != \"mcmc\" or key[-1]:\n",
    "            continue\n",
    "        mcmc_sigma = fit[\"mean\"][\"rate_coef\"] / fit[\"std\"][\"rate_coef\"]\n",
    "        plt.scatter(svi_sigma.numpy(), mcmc_sigma.numpy(), 10, lw=0, alpha=0.5, label=key[1])\n",
    "    plt.xscale(\"symlog\")\n",
    "    plt.yscale(\"symlog\")\n",
    "    plt.title(\"SVI versus MCMC: |μ|/σ = statistical significance\")\n",
    "    plt.xlabel(\"SVI estimate\")\n",
    "    plt.ylabel(\"MCMC estimate\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "if mcmc_fits:\n",
    "    plot_svi_mcmc_sigma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_volcano(mean, std, filenames=(), linthresh=2, top_k=60):\n",
    "    xs = mean\n",
    "    ys = mean.abs() / std\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    ys, idx = ys.sort(0, descending=True)\n",
    "    xs = xs[idx]\n",
    "    pos = (0 < xs) & (xs < math.inf)\n",
    "    neg = (-math.inf < xs) & (xs < 0)\n",
    "    ys_pos, ys_neg = ys[pos], ys[neg]\n",
    "    xs_pos, xs_neg = xs[pos], xs[neg]\n",
    "    idx_pos, idx_neg = idx[pos], idx[neg]\n",
    "    N = top_k\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\")\n",
    "    for mask in [pos, neg]:\n",
    "        xs_mask, ys_mask = xs[mask], ys[mask]\n",
    "        plt.plot(xs_mask[:N], ys_mask[:N], 'k.', lw=0, markersize=2, zorder=10)\n",
    "        plt.plot(xs_mask[N:], ys_mask[N:], 'k.', lw=0, markersize=2, zorder=10, color=\"#aaa\")\n",
    "    plt.xlabel(\"effect size (R / R_A = exp(μ))\")\n",
    "    xticks = [0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15]\n",
    "    plt.xticks(list(map(math.log, xticks)), list(map(str, xticks)))\n",
    "    plt.ylabel(\"statistical significance (|μ|/σ)\")\n",
    "    lpad = 0.33 if any(\",\" in mutations[i] for i in idx_neg[:N].tolist()) else 0.18\n",
    "    rpad = 0.33 if any(\",\" in mutations[i] for i in idx_pos[:N].tolist()) else 0.18\n",
    "    plt.xlim(x0 - (x1 - x0) * lpad, x1 + (x1 - x0) * rpad)\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100] if y < y1]\n",
    "    plt.yticks(yticks, list(map(str, yticks)))\n",
    "    p95 = dist.Normal(0, 1).icdf(torch.tensor(0.95)).item()\n",
    "    plt.plot([x0, x1], [p95, p95], 'k--', alpha=0.2)\n",
    "    plt.text(0.2 * x0 + 0.8 * x1, p95 * 0.95, \"95% probabililty\\nof correct sign(μ)\",\n",
    "             fontsize=7, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "             alpha=0.8, zorder=100)\n",
    "        \n",
    "    colors = {\"N\": \"blue\", \"S\": \"red\", \"M\": \"purple\", \"ORF3a\": \"darkgreen\"}\n",
    "    ax = plt.gca()\n",
    "    t = (ax.transScale + ax.transLimits).inverted()\n",
    "    for i in range(N):\n",
    "        x = x0\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        plt.plot([x, xs_neg[i]], [y, ys_neg[i]], color='gray', lw=0.2)\n",
    "        name = mutations[int(idx_neg[i])]\n",
    "        plt.text(x, y, name + \" \", color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"right\")\n",
    "    for i in range(N):\n",
    "        x = x1\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        name = mutations[int(idx_pos[i])]\n",
    "        plt.plot([x, xs_pos[i]], [y, ys_pos[i]], color='gray', lw=0.2)\n",
    "        plt.text(x, y, \" \" + name, color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.tight_layout()\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_volcano(best_fit[\"mean\"][\"rate_coef\"], best_fit[\"std\"][\"rate_coef\"], linthresh=50,\n",
    "             filenames=[\"paper/volcano.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrocov.sarscov2 import GENE_TO_POSITION, aa_mutation_to_position\n",
    "\n",
    "def plot_manhattan(mean, std, top_k=75, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    even = (gene_ids % 2 == 0) & (mean > 0)\n",
    "    odd = (gene_ids % 2 == 1) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"Increased transmissibility of {len(mutations)} mutations\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    mean_scale = 50 / mean.max().item()\n",
    "    for mask, color in zip([even, odd], [\"darkblue\", \"darkred\"]):\n",
    "        plt.scatter(position[mask].numpy(), sigma[mask].numpy(),\n",
    "                    mean_scale * mean[mask].numpy(), color=color, alpha=0.5, lw=0)\n",
    "    special = {\"S\": [], \"N\": [], \"ORF3a\": []}  # Many hits, plot with lines\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene in special:\n",
    "            special[gene].append((y, x, name))\n",
    "            continue\n",
    "        plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                 verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    for special_ in special.values():\n",
    "        special_.sort(reverse=True)\n",
    "    y_bounds = {k: (min(y for (y, _, _) in v), max(y for (y, _, _) in v))\n",
    "                for k, v in special.items() if v}\n",
    "    for i, (y, x, name) in enumerate(special[\"S\"]):\n",
    "        lb, ub = y_bounds[\"S\"]\n",
    "        lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "        y_label = 0.2 * y + 0.8 * (ub + (lb - ub) * (i / (len(special[\"S\"]) - 0.99)))\n",
    "        x_label = GENE_TO_POSITION[\"S\"][1] - 1000\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    for gene in [\"N\", \"ORF3a\"]:\n",
    "        for i, (y, x, name) in enumerate(special[gene]):\n",
    "            lb, ub = y_bounds[gene]\n",
    "            lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "            y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[gene]) - 0.99)))\n",
    "            x_label = GENE_TO_POSITION[gene][1] + 200\n",
    "            plt.text(x_label, y_label, name, fontsize=6,\n",
    "                     verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "            plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "        \n",
    "    start_end = list(GENE_TO_POSITION.values())\n",
    "    plt.xlim(start_end[0][0], start_end[-1][-1])\n",
    "    xticks = []\n",
    "    for i, (gene, (start, end)) in enumerate(GENE_TO_POSITION.items()):\n",
    "        if gene == \"ORF14\":\n",
    "            continue  # skip overlapping frame\n",
    "        plt.axvline(start, lw=0.1)\n",
    "        plt.axvline(end, lw=0.1)\n",
    "        xticks.extend([start, end])\n",
    "        plt.text((start + end) / 2, -y1 / 50, gene, rotation=-90,\n",
    "                 fontsize=6, verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "    plt.xticks(xticks, labels=())\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"μ / σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_manhattan(best_fit[\"mean\"][\"rate_coef\"], best_fit[\"std\"][\"rate_coef\"],\n",
    "               filenames=[\"paper/manhattan.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_upper_east_side(mean, std, top_k=120, filenames=()):\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    y1 = sigma.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert len(mean) == len(mutations)\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    mask = (gene_ids == gene_id[\"N\"]) & (mean > 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"Increased transmissibility of mutations within N gene\"\n",
    "              \" (dots scaled by effect size)\")\n",
    "    mean_scale = 50 / mean.max().item()\n",
    "    plt.scatter(position[mask].numpy(), sigma[mask].numpy(),\n",
    "                mean_scale * mean[mask].numpy(), color=\"darkblue\", alpha=0.5, lw=0)\n",
    "    special = []  # Many hits, plot with lines\n",
    "    z0 = 28800\n",
    "    z1 = 29000\n",
    "    for i in sigma.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(sigma[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene != \"N\":\n",
    "            continue\n",
    "        if z0 < x < z1:\n",
    "            special.append((y, x, name))\n",
    "        else:\n",
    "            plt.text(x, y + y1/80, name, fontsize=6,\n",
    "                     verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    special.sort(reverse=True)\n",
    "    lb = min(y for (y, _, _) in special)\n",
    "    ub = max(y for (y, _, _) in special)\n",
    "    lb, ub = lb * 0.5, ub * 0.5 + y1 * 0.5\n",
    "    for i, (y, x, name) in enumerate(special):\n",
    "        y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special) - 0.99)))\n",
    "        x_label = z1\n",
    "        plt.text(x_label, y_label, name, fontsize=6,\n",
    "                 verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        plt.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    start, end = GENE_TO_POSITION[\"N\"]\n",
    "    plt.xlim(start, end)\n",
    "    xticks = [start]\n",
    "    while xticks[-1] + 150 < end:\n",
    "        xticks.append(xticks[-1] + 150)\n",
    "    labels = [str((x - start) // 3) for x in xticks]\n",
    "    plt.xticks(xticks, labels)\n",
    "    plt.xlabel(\"amino acid position within N gene\")\n",
    "    plt.ylim(0, None)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.1)\n",
    "    plt.ylabel(\"μ / σ\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_upper_east_side(best_fit[\"mean\"][\"rate_coef\"], best_fit[\"std\"][\"rate_coef\"],\n",
    "                     filenames=[\"paper/upper_east_side.png\"], top_k=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_prevalence(fit, filenames=()):\n",
    "    rate = fit[\"median\"][\"rate_coef\"] @ features.T\n",
    "    rate = rate - rate[lineage_id[\"A\"]]\n",
    "    R = rate.exp()\n",
    "    init = fit[\"median\"][\"init\"] + dataset[\"local_time\"][-2, :, None] * rate\n",
    "    init = init - init.logsumexp(-1, True)\n",
    "    cases = torch.einsum(\"ps,p->s\", init.exp(), weekly_cases[-2])\n",
    "    cases = cases / mutrans.TIMESTEP\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(R, cases, lw=0, alpha=0)\n",
    "    for name, i in lineage_id.items():\n",
    "        if cases[i] <= 1.1:\n",
    "            continue\n",
    "        plt.text(R[i], cases[i], name, fontsize=8, alpha=0.8,\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",)\n",
    "    plt.ylabel(\"confirmed cases / day\")\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xscale(\"log\")\n",
    "    plt.ylim(1, None)\n",
    "    plt.xlim(0.9, None)\n",
    "    lb10 = math.floor(10 * R.min().item())\n",
    "    ub10 = math.ceil(10 * R.max().item())\n",
    "    xticks = [x10 / 10 for x10 in range(lb10, ub10 + 1)]\n",
    "    plt.xticks(xticks, list(map(str, xticks)))\n",
    "    plt.xlabel(\"relative reproduction number $R_{strain} / R_A$\")\n",
    "    plt.title(f\"Transmissibility of {len(lineage_id)} PANGO lineages\")\n",
    "    plt.tight_layout()\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "plot_prevalence(best_fit, [\"paper/strain_prevalence.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(fit, queries, num_strains=5, months_ahead=3):\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    fig, axes = plt.subplots(len(queries), figsize=(6, 1 + 1.2 * len(queries)), sharex=True)\n",
    "    median = fit[\"median\"]\n",
    "    rate = median[\"rate\"]\n",
    "    init = median[\"init\"]\n",
    "    local_time = dataset[\"local_time\"]\n",
    "    probs = (init + rate * local_time[:, :, None]).softmax(-1)  # [T, P, S]\n",
    "    predicted = probs * weekly_cases[:, :, None]  # [T, P, S]\n",
    "    ids = torch.tensor([i for name, i in location_id.items()\n",
    "                        if any(q in name for q in queries)])\n",
    "    mean_strains = weekly_strains[:, ids].sum([1])\n",
    "    mean_strains = mean_strains / (1e-8 + mean_strains.sum(-1, True))\n",
    "    strain_ids = mean_strains.sum(0).sort(-1, descending=True).indices\n",
    "    strain_ids = strain_ids[:num_strains]\n",
    "    colors = [f\"C{i}\" for i in range(10)]\n",
    "    assert len(colors) >= num_strains\n",
    "    for row, (query, ax) in enumerate(zip(queries, axes)):\n",
    "        ids = torch.tensor([i for name, i in location_id.items() if query in name])\n",
    "        print(query + \":\")\n",
    "        for name in location_id:\n",
    "            if query in name:\n",
    "                print(\"  \" + name)\n",
    "        pred = predicted[:, ids].sum(1)\n",
    "        pred /= pred.sum(-1, True)\n",
    "        obs = weekly_strains[:, ids].sum(1)\n",
    "        obs /= obs.sum(-1, True)\n",
    "        for s, color in zip(strain_ids, colors):\n",
    "            ax.plot(pred[:, s], color=color)\n",
    "            ax.plot(obs[:, s], color=color, lw=0, marker='o', markersize=3,\n",
    "                    label=lineage_id_inv[s] if row == 0 else None)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks(())\n",
    "        ax.set_ylabel(query)\n",
    "        ax.set_xlim(0, len(weekly_strains))\n",
    "        if row == len(axes) - 1:\n",
    "            ax.set_xlabel(\"Time (week after 2019-12-01)\")\n",
    "        if row == 0:\n",
    "            ax.legend(loc=\"upper left\", fontsize=6)\n",
    "        elif row == 1:\n",
    "            ax.plot([], lw=0, marker='o', markersize=3, color='gray', label=\"observed\")\n",
    "            ax.plot([], color='gray', label=\"predicted\")\n",
    "            ax.legend(loc=\"upper left\", fontsize=6)\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "\n",
    "plot_forecast(best_fit,\n",
    "              queries=[\"/ England\", \"/ Wales\"],\n",
    "              # queries=[\"England\", \"Wales\", \"Scotland\", \"Denmark\", \"USA\"],\n",
    "              num_strains=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a table of top mutations and their stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mutations(fit, names):\n",
    "    mean = fit[\"mean\"][\"rate_coef\"]\n",
    "    std = fit[\"std\"][\"rate_coef\"]\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    ranks = sigma.sort(0, descending=True).indices.tolist()\n",
    "    assert len(ranks) == len(mutations)\n",
    "    ranked = [mutations[k] for k in ranks]\n",
    "    ranks = {m: i for i, m in enumerate(ranked)}\n",
    "    print(\"Mut'n\\tRank\\tEstimate\")\n",
    "    for name in names:\n",
    "        i = mutations.index(name)\n",
    "        print(\"{}\\t{}\\t{:0.3g} ± {:0.2g}\".format(name, ranks[name], mean[i], std[i]))\n",
    "\n",
    "print(\"SVI:\")\n",
    "rank_mutations(svi_fit, [\"S:D614G\", \"S:N501Y\", \"S:E484K\", \"S:L452R\"])\n",
    "if mcmc_fits:\n",
    "    print(\"MCMC:\")\n",
    "    rank_mutations(mcmc_fit, [\"S:D614G\", \"S:N501Y\", \"S:E484K\", \"S:L452R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_features = torch.zeros_like(features)\n",
    "for c, child in enumerate(lineage_id_inv):\n",
    "    child = pangolin.decompress(child)\n",
    "    parent = child\n",
    "    while True:\n",
    "        parent = \"A\" if parent == \"A\" else pangolin.get_parent(parent)\n",
    "        try:\n",
    "            p = lineage_id[pangolin.compress(parent)]\n",
    "            break\n",
    "        except KeyError:\n",
    "            continue\n",
    "    parent_features[c] = features[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emergences(i):\n",
    "    delta = features[:, i] - parent_features[:, i]\n",
    "    emerged = set((delta > 0.5).nonzero(as_tuple=True)[0].tolist())\n",
    "    emerged.add(delta.argmax().item())\n",
    "    result = []\n",
    "    for k in sorted(emerged):\n",
    "        name = lineage_id_inv[k]\n",
    "        longname = pangolin.decompress(name)\n",
    "        result.append(name if name == longname else f\"{name} ({longname})\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mutation_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    mean = fit[\"mean\"][\"rate_coef\"]\n",
    "    std = fit[\"std\"][\"rate_coef\"]\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    if \"samples\" in fit:\n",
    "        lb, ub = stats.confidence_interval(0.95, fit[\"samples\"][\"rate_coef\"])\n",
    "    else:\n",
    "        lb, ub = dist.Normal(mean, std).icdf(torch.tensor([0.025, 0.975])[:, None])\n",
    "    R_RA = mean.exp()  # mean is in units of generation time.\n",
    "    lineage_counts = weekly_strains.sum((0, 1))\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"mutation\", \"{:s}\"),\n",
    "        (\"mean/stddev\", \"{:0.6g}\"),\n",
    "        (\"mean\", \"{:0.6g}\"),\n",
    "        (\"95% ci lower\", \"{:0.6g}\"),\n",
    "        (\"95% ci upper\", \"{:0.6g}\"),\n",
    "        (\"R / R_A\", \"{:0.6g}\"),\n",
    "        (\"emerged in lineages\", \"{:s}\"),  \n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(sigma.sort(0, descending=True).indices.tolist()):\n",
    "            emerged = find_emergences(i)\n",
    "            f.write(row.format(\n",
    "                rank + 1, mutations[i],\n",
    "                sigma[i], mean[i], lb[i], ub[i], R_RA[i], \", \".join(emerged)\n",
    "            ))\n",
    "\n",
    "write_mutation_table(best_fit, \"paper/mutations.tsv\")\n",
    "pd.read_csv(\"paper/mutations.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lineage_bdays(exclude_first=10):\n",
    "    lineage_days = defaultdict(list)\n",
    "    for lineage, day in zip(columns[\"lineage\"], columns[\"day\"]):\n",
    "        lineage = pangolin.decompress(lineage)\n",
    "        lineage_days[lineage].append(day)\n",
    "    lineage_bday = {}\n",
    "    for lineage, days in list(lineage_days.items()):\n",
    "        days.sort()\n",
    "        lineage_bday[lineage] = days[min(exclude_first, len(days) // 10)]\n",
    "    start_date = datetime.datetime.strptime(mutrans.START_DATE, \"%Y-%m-%d\")\n",
    "    return {\n",
    "        lineage: (start_date + datetime.timedelta(days=day)).strftime(\"%Y-%m-%d\")\n",
    "        for lineage, day in lineage_bday.items()\n",
    "    }\n",
    "\n",
    "lineage_bday = estimate_lineage_bdays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strain_table(svi_fit, mcmc_fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    R_mean = mcmc_fit[\"mean\"][\"rate\"].exp()\n",
    "    R_sample = mcmc_fit[\"samples\"][\"rate\"].exp()\n",
    "    RA = R_mean[lineage_id[\"A\"]].item()\n",
    "    R_RA = R_mean / RA\n",
    "    lb, ub = stats.confidence_interval(0.95, R_sample / RA)\n",
    "    logits = svi_fit[\"median\"][\"init\"] + dataset[\"local_time\"][..., None] * svi_fit[\"median\"][\"rate\"]\n",
    "    probs = (logits - logits.logsumexp(-1, True)).exp()\n",
    "    cases = torch.einsum(\"tps,tp->ts\", probs, weekly_cases)\n",
    "    cases_per_day = cases[-2] / mutrans.TIMESTEP\n",
    "    cases_total = cases.sum(0)\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"strain\", \"{:s}\"),\n",
    "        (\"R / R_A\", \"{:.6g}\"),\n",
    "        (\"95% ci lower\", \"{:.6g}\"),\n",
    "        (\"95% ci upper\", \"{:.6g}\"),\n",
    "        (\"confirmed cases / day\", \"{:.6g}\"),\n",
    "        (\"confirmed cases total\", \"{:.6g}\"),\n",
    "        (\"birthday\", \"{:s}\"),\n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(R_RA.sort(0, descending=True).indices.tolist()):\n",
    "            lineage = lineage_id_inv[i]\n",
    "            f.write(row.format(\n",
    "                rank + 1, lineage,\n",
    "                R_RA[i], lb[i], ub[i], cases_per_day[i], cases_total[i],\n",
    "                lineage_bday[pangolin.decompress(lineage)],\n",
    "            ))\n",
    "\n",
    "if \"samples\" in best_fit:\n",
    "    write_strain_table(svi_fit, best_fit, \"paper/strains.tsv\")\n",
    "    pd.read_csv(\"paper/strains.tsv\", sep=\"\\t\")\n",
    "else:\n",
    "    print(\"ERROR cannot generate plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with deep mutational scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare with [(Starr et al. 2020)](https://www.sciencedirect.com/science/article/pii/S0092867420310035) who study S mutations affecting folding and ACE2 binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S0092867420310035-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = {f\"S:{m}\": float(e) for m, e in zip(df[\"mutation\"], df[\"expr_avg\"])}\n",
    "binding = {f\"S:{m}\": float(b) for m, b in zip(df[\"mutation\"], df[\"bind_avg\"])}\n",
    "print(sum(1 for m in mutations if m in folding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compare with [(Greaney et al. 2021)](https://www.sciencedirect.com/science/article/pii/S1931312820306247) who study antibody escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mutation-studies/1-s2.0-S1931312820306247-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape = {\n",
    "    f\"S:{w}{s}{m}\": float(e)\n",
    "    for w, s, m, e in zip(df[\"wildtype\"], df[\"site\"], df[\"mutation\"], df[\"mut_escape\"])\n",
    "}\n",
    "print(sum(1 for m in mutations if m in escape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "ms = [m for m in mutations if m in escape]\n",
    "y = mcmc_fit[\"mean\"][\"rate_coef\"][[i for i, m in enumerate(mutations) if m in escape]].numpy()\n",
    "axes[0].set_ylabel(\"Δ log R\")\n",
    "for name, ax in zip([\"folding\", \"binding\", \"escape\"], axes):\n",
    "    scan = locals()[name]\n",
    "    x = torch.tensor([scan[m] for m in ms]).numpy()\n",
    "    # ax.scatter(x, y, alpha=0.5, lw=0)\n",
    "    for xm, ym, m in zip(x, y, ms):\n",
    "        ax.text(xm, ym, m[2:], fontsize=6,\n",
    "                verticalalignment=\"center\", horizontalalignment=\"center\")\n",
    "    ax.set_xlim(1.08 * x.min() - 0.08 * x.max(), 1.08 * x.max() - 0.08 * x.min())\n",
    "    ax.set_ylim(1.05 * y.min() - 0.05 * y.max(), 1.05 * y.max() - 0.05 * y.min())\n",
    "    ax.set_xlabel(f\"{name} (ρ = {correlation(x, y):0.2g})\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "axes[2].set_xscale(\"log\")\n",
    "axes[2].set_xlim(x.min() ** 1.08 / x.max() ** 0.08, x.max() ** 1.08 / x.min() ** 0.08)\n",
    "axes[1].set_title(f\"Comparison of {len(ms)} S gene mutations to deep scanning\")\n",
    "plt.subplots_adjust(wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say whether these correlations are meaningful, as they are dominated by a few outliers.\n",
    "\n",
    "Let's fit a linear model regressing transmissibility against theses deep scanning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "def fit_model(fit):\n",
    "    trans_data = fit[\"mean\"][\"rate_coef\"][[i for i, m in enumerate(mutations) if m in escape]]\n",
    "    folding_data = torch.tensor([folding[m] for m in ms])\n",
    "    binding_data = torch.tensor([binding[m] for m in ms])\n",
    "    escape_data = torch.tensor([escape[m] for m in ms])\n",
    "    \n",
    "    def model():\n",
    "        coef = pyro.sample(\"coef\", dist.Normal(0, 10).expand([5]).to_event(1))\n",
    "        t, f, b, e, be = coef.unbind(-1)\n",
    "        noise = pyro.sample(\"noise\", dist.LogNormal(0, 2))\n",
    "        with pyro.plate(\"data\", len(trans_data)):\n",
    "            pred = (\n",
    "                t + f * folding_data + b * binding_data + e * escape_data\n",
    "                + be * binding_data * escape_data\n",
    "            )\n",
    "            pyro.sample(\"trans\", dist.Normal(pred, noise), obs=trans_data)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    elbo = Trace_ELBO(num_particles=100, vectorize_particles=True)\n",
    "    svi = SVI(model, guide, Adam({\"lr\": 0.2}), elbo)\n",
    "    for step in range(201):\n",
    "        loss = svi.step()\n",
    "        if step % 20 == 0:\n",
    "            print(f\"step {step} loss = {loss:0.4g}\")\n",
    "    loc, scale = guide._loc_scale()\n",
    "    print(\"Model:\")\n",
    "    print(\"transmissibility = t + f folding + b binding + e escape + be binding escape\")\n",
    "    print(\"Learned coefficients:\")\n",
    "    for k, l, s in zip(\"t f b e be\".split(), loc.tolist(), scale.tolist()):\n",
    "        print(f\"{k} = {l:0.4g} +- {s:0.2f}\")\n",
    "        \n",
    "fit_model(mcmc_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter([n for n in columns[\"virus_name\"] if \"-CDC-2-\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"USA\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"United King\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"North America \" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"Europe \" in n]).most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_fits = {k[-1]: v for k, v in fits.items() if k[-1]\n",
    "                if (not mcmc_fits or k[0] == \"mcmc\")}\n",
    "for key in holdout_fits:\n",
    "    print(key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = [\n",
    "    \"only Europe\",\n",
    "    \"excluding Europe\",\n",
    "    \"only North America\",\n",
    "    \"excluding North America\",\n",
    "    # \"only the USA\",\n",
    "    # \"excluding the USA\",\n",
    "    # \"excluding the UK\",\n",
    "    # \"only the UK\",\n",
    "    # \"only CDC data\",\n",
    "    # \"only CDC NS3 data\",\n",
    "]\n",
    "holdout_fits = dict(zip(aliases, holdout_fits.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        return fit[\"mean\"][\"rate_coef\"]\n",
    "    mean1 = get_mean(fit1)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in [mean1] + means)\n",
    "    x1 = max(mean.max().item() for mean in [mean1] + means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(len(holdouts) * 3, 3), sharey=True)\n",
    "    fig.suptitle(\"Δ log R for {} mutations estimated from full versus subsets of data\"\n",
    "                 .format(len(fit1[\"mutations\"])))\n",
    "    for ax, (name, fit2), mean2 in zip(axes, holdouts.items(), means):\n",
    "        mutations = sorted(set(fit1[\"mutations\"]) & set(fit2[\"mutations\"]))\n",
    "        means = []\n",
    "        for fit, mean in ((fit1, mean1), (fit2, mean2)):\n",
    "            m_to_i = {m: i for i, m in enumerate(fit[\"mutations\"])}\n",
    "            idx = torch.tensor([m_to_i[m] for m in mutations])\n",
    "            means.append(mean[idx])\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 50, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 30, alpha=0.3, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(means[0], means[1])))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_mutation_agreements(best_fit, holdout_fits, [\"paper/mutation_agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        rate = fit[\"median\"][\"rate\"]\n",
    "        return (rate - rate[lineage_id[\"A\"]]).exp()\n",
    "    mean1 = get_mean(fit1)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in [mean1] + means)\n",
    "    x1 = max(mean.max().item() for mean in [mean1] + means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(holdouts), figsize=(len(holdouts) * 3, 3), sharey=True)\n",
    "    fig.suptitle(\"$R_{{lineage}} / R_A$ for {} lineages esimated from full versus subsets of data\"\n",
    "                 .format(len(lineage_id)))\n",
    "    for ax, name, mean2 in zip(axes, holdouts, means):\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(mean2.numpy(), mean1.numpy(), 50, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(mean2.numpy(), mean1.numpy(), 30, alpha=0.3, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(correlation(mean1, mean2)))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_xlabel(name)\n",
    "    axes[0].set_ylim(lb, ub)\n",
    "    axes[0].set_ylabel(\"full data\")\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_strain_agreements(best_fit, holdout_fits, [\"paper/lineage_agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_subset_boxplot(fits, rankby=\"s\", top_k=20, filenames=()):\n",
    "    best_fit = next(iter(fits.values()))\n",
    "    if rankby == \"s\":\n",
    "        rankby = best_fit[\"mean\"][\"rate_coef\"] / best_fit[\"std\"][\"rate_coef\"]\n",
    "        title = f\"Top {top_k} most statistically significant mutations\"\n",
    "    elif rankby == \"t\":\n",
    "        rankby = best_fit[\"mean\"][\"rate_coef\"]\n",
    "        title = f\"Top {top_k} most transmissible mutations\"\n",
    "    else: raise ValueError(rankby)\n",
    "    top_indices = rankby.sort(0, descending=True).indices[:top_k]\n",
    "    top_mutations = [mutations[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"rate_coef\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"mean\"][\"rate_coef\"][top_indices]\n",
    "            std = fit[\"std\"][\"rate_coef\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean(0)\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "    \n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'pink', 'lightgreen']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 9})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               # labels=[x.replace(\":\", \":\\n\") for x in top_mutations],\n",
    "               labels=top_mutations, rotation=-90, fontsize=9)\n",
    "    plt.ylabel(\"Δ log R\")\n",
    "    plt.title(title)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "for name in [\"Europe\", \"North America\"]:\n",
    "    name_ = name.lower().replace(\" \", \"_\")\n",
    "    plot_mutation_subset_boxplot({\n",
    "        f\"World w/o {name}\": holdout_fits[f\"excluding {name}\"],\n",
    "        \"World\": best_fit,\n",
    "        f\"{name} only\": holdout_fits[f\"only {name}\"],\n",
    "    }, filenames=[f\"paper/mutation_{name_}_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_subset_boxplot(fits, top_k=20, filenames=()):\n",
    "    best_fit = next(iter(fits.values()))\n",
    "    top_indices = best_fit[\"mean\"][\"rate\"].sort(0, descending=True).indices[:top_k]\n",
    "    top_lineages = [lineage_id_inv[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"rate\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"median\"][\"rate\"][top_indices]\n",
    "            std = fit[\"std\"][\"rate\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        samples = samples - fit[\"median\"][\"rate\"][lineage_id[\"A\"]]\n",
    "        samples = samples.exp()\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean()\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'pink', 'lightgreen']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 10})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               labels=top_lineages, rotation=-90)\n",
    "    plt.ylabel(\"$R / R_A$\")\n",
    "    plt.title(f\"Top {top_k} most transmissible lineages\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "for name in [\"Europe\", \"North America\"]:\n",
    "    name_ = name.lower().replace(\" \", \"_\")\n",
    "    plot_strain_subset_boxplot({\n",
    "        f\"World w/o {name}\": holdout_fits[f\"excluding {name}\"],\n",
    "        \"World\": best_fit,\n",
    "        f\"{name} only\": holdout_fits[f\"only {name}\"],\n",
    "    }, filenames=[f\"paper/strain_{name_}_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
