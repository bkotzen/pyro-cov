{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore GISAID data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from collections import Counter\n",
    "from pyrocov import mutrans, pangolin\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1851054 rows\n",
      "['lineage', 'virus_name', 'accession_id', 'collection_date', 'location', 'add_location', 'day']\n"
     ]
    }
   ],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "print(\"loaded {} rows\".format(len(columns[\"day\"])))\n",
    "print(list(columns.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    832417 B.1.1.7\n",
      "     88799 B.1.2\n",
      "     80377 B.1\n",
      "     70042 B.1.177\n",
      "     46762 B.1.1\n",
      "     31619 B.1.617.2\n",
      "     31437 B.1.429\n",
      "     25715 P.1 (aka B.1.1.28.1)\n",
      "     23204 B.1.160\n",
      "     21723 B.1.351\n",
      "     21602 B.1.526\n",
      "     18691 B.1.1.519\n",
      "     16986 B.1.1.214\n",
      "     13143 B.1.427\n",
      "     13025 B.1.221\n",
      "     13004 B.1.177.21\n",
      "     12857 B.1.258\n",
      "     12332 D.2 (aka B.1.1.25.2)\n",
      "     10623 B.1.243\n",
      "      9975 B.1.526.2\n"
     ]
    }
   ],
   "source": [
    "strain_counts = Counter(columns[\"lineage\"])\n",
    "for strain, count in strain_counts.most_common(20):\n",
    "    short = pangolin.compress(strain)\n",
    "    long = pangolin.decompress(strain)\n",
    "    assert strain == long, (strain, long)\n",
    "    if short == long:\n",
    "        print(f\"{count: >10d} {short}\")\n",
    "    else:\n",
    "        print(f\"{count: >10d} {short} (aka {long})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for location in columns[\"location\"]:\n",
    "    parts = location.split(\"/\")\n",
    "    if len(parts) < 2:\n",
    "        continue\n",
    "    parts = tuple(p.strip() for p in parts[:3])\n",
    "    counts[parts] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia\n",
      "Brazil\n",
      "Canada\n",
      "Denmark\n",
      "Finland\n",
      "France\n",
      "Germany\n",
      "Iceland\n",
      "Ireland\n",
      "Italy\n",
      "Japan\n",
      "Luxembourg\n",
      "Netherlands\n",
      "Portugal\n",
      "Spain\n",
      "Sweden\n",
      "Switzerland\n",
      "USA\n",
      "United Kingdom\n"
     ]
    }
   ],
   "source": [
    "fine_countries = set()\n",
    "for parts, count in counts.items():\n",
    "    if count >= 5000:\n",
    "        fine_countries.add(parts[1])\n",
    "fine_countries = list(sorted(fine_countries))\n",
    "print(\"\\n\".join(fine_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346691\tEurope / United Kingdom / England\n",
      "43553\tEurope / United Kingdom / Scotland\n",
      "34153\tEurope / United Kingdom / Wales\n",
      "6933\tEurope / United Kingdom / Northern Ireland\n",
      "171\tEurope / United Kingdom / England / South Yorkshire\n",
      "107\tEurope / United Kingdom / England / London\n",
      "11\tEurope / United Kingdom / England / Derbyshire\n",
      "2\tEurope / United Kingdom / England / Yorkshire / Sheffield\n",
      "2\tEurope / United Kingdom\n",
      "1\tEurope / United Kingdom / England / Northamtonshire\n",
      "1\tEurope / United Kingdom / England / Nottinghamhisre\n",
      "1\tEurope / United Kingdom / Wales / Cardiff\n",
      "1\tEurope / United Kingdom / England / Warwickshire\n",
      "1\tEurope / United Kingdom / London\n",
      "1\tEurope / United Kingdom / Scotland / Fraserburg\n"
     ]
    }
   ],
   "source": [
    "locations = Counter(columns[\"location\"])\n",
    "print(\"\\n\".join(f\"{c}\\t{p}\" for p, c in locations.most_common() if \"United Kingdom\" in p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    filename = \"results/mutrans.data.single.pt\"\n",
    "    if os.path.exists(filename):\n",
    "        dataset = torch.load(filename)\n",
    "    else:\n",
    "        dataset = mutrans.load_gisaid_data()\n",
    "        torch.save(dataset, filename)\n",
    "    dataset.update(mutrans.load_jhu_data(dataset))\n",
    "    return dataset\n",
    "\n",
    "dataset = load_data()\n",
    "locals().update(dataset)\n",
    "for k, v in sorted(dataset.items()):\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k} \\t{type(v).__name__} of shape {tuple(v.shape)}\")\n",
    "    else:\n",
    "        print(f\"{k} \\t{type(v).__name__} of size {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = weekly_strains + 1 / weekly_strains.size(-1)\n",
    "probs /= probs.sum(-1, True)\n",
    "logits = probs.log()\n",
    "logits -= logits.median(-1, True).values\n",
    "plt.hist(logits.reshape(-1).numpy(), bins=100)\n",
    "plt.yscale(\"symlog\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits -= logits.mean(-1, True)\n",
    "plt.hist(logits.reshape(-1).numpy(), bins=100)\n",
    "plt.yscale(\"symlog\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
