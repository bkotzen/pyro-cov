{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "from pyrophylo.pangolin import find_edges, canonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "print(columns.keys())\n",
    "print(len(columns[\"day\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = columns[\"lineage\"]\n",
    "print(f\"Top 12 of {len(set(lineages))} lineages\")\n",
    "print(\"-\" * 30)\n",
    "for lineage, count in Counter(lineages).most_common(12):\n",
    "    print(f\"{count: >10d} {lineage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_data = Counter()\n",
    "location_id = {}\n",
    "lineage_id = {}\n",
    "for day, location, lineage in zip(columns[\"day\"], columns[\"location\"], columns[\"lineage\"]):\n",
    "    parts = location.split(\" / \")\n",
    "    if len(parts) < 2:\n",
    "        continue\n",
    "    location = \" / \".join(p.strip() for p in parts)\n",
    "    x = location_id.setdefault(location, len(location_id))\n",
    "    s = lineage_id.setdefault(lineage, len(lineage_id))\n",
    "    t = day // 7\n",
    "    sparse_data[t, x, s] += 1\n",
    "    \n",
    "T = 1 + max(columns[\"day\"]) // 7\n",
    "P = len(location_id)\n",
    "S = len(lineage_id)\n",
    "dense_data = torch.zeros(T, P, S)\n",
    "for (t, p, s), n in sparse_data.items():\n",
    "    dense_data[t, p, s] = n\n",
    "print(dense_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = find_edges(list(lineage_id))\n",
    "edges = torch.tensor([[lineage_id[u], lineage_id[v]] for u, v in edges], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(dense_data, edges):\n",
    "    T, P, S = dense_data.shape\n",
    "    time_plate = pyro.plate(\"time\", T, dim=-2)\n",
    "    place_plate = pyro.plate(\"place\", P, dim=-1)\n",
    "    time = torch.arange(float(T)) * 7 / 365.25  # in years\n",
    "    \n",
    "    # Assume relative growth rate depends on strain but not time or place.\n",
    "    log_rate = pyro.sample(\n",
    "        \"log_rate\",\n",
    "        dist.Normal(0, 1).expand([S]).to_event(1),\n",
    "    )\n",
    "    # Assume related strains have similar relative growth rate.\n",
    "    # We model this as Cauchy whose heavy tails lead to a jump process.\n",
    "    tree_scale = pyro.sample(\"tree_scale\", dist.LogNormal(-5, 5))\n",
    "    with pyro.plate(\"edges\", len(edges), dim=-1):\n",
    "        u, v = edges.unbind(-1)\n",
    "        pyro.sample(\n",
    "            \"rate_change\",\n",
    "            dist.Cauchy(0, tree_scale),\n",
    "            obs=log_rate[..., u] - log_rate[..., v],\n",
    "        )\n",
    "\n",
    "    # Assume places differ only in their initial infection count.\n",
    "    with place_plate:\n",
    "        log_init = pyro.sample(\n",
    "            \"log_init\",\n",
    "            dist.LogNormal(0, 10).expand([S]).to_event(1),\n",
    "        )\n",
    "\n",
    "    # Finally observe overdispersed counts.\n",
    "    dispersion = pyro.sample(\"dispersion\", dist.LogNormal(0, 1))\n",
    "    with time_plate, place_plate:\n",
    "        base_rate = (log_init + log_rate * time[:, None, None]).softmax(dim=-1)\n",
    "        pyro.sample(\n",
    "            \"obs\",\n",
    "            dist.DirichletMultinomial(\n",
    "                total_count=dense_data.sum(-1).max(),\n",
    "                concentration=dispersion * base_rate,\n",
    "                is_sparse=True,  # uses a faster algorithm\n",
    "            ),\n",
    "            obs=dense_data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoNormal(model)\n",
    "optim = ClippedAdam({\"lr\": 0.01})\n",
    "svi = SVI(model, guide, optim, Trace_ELBO())\n",
    "for step in range(501):\n",
    "    loss = svi.step(dense_data, edges)\n",
    "    if step % 10 == 0:\n",
    "        print(f\"step {step} loss = {loss:0.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
