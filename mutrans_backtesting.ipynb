{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for backtesting mutation growth rate paper\n",
    "\n",
    "This notebook generates plots for the [paper/](paper/) directory. This assumes you've alread run\n",
    "```sh\n",
    "make update                       # Downloads and preprocesses data.\n",
    "python mutrans.py --backtesting-max-day 150,200,250,300,350,400,450,500,550 # Fits models with different data truncations\n",
    "```\n",
    "Note that `make update` takes a couple hours the first time it is run (mostly in sequence alignment), and `mutrans.py` takes about 15 minutes on a GPU (will take much longer if no GPU is available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import logging\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyrocov import mutrans, pangolin, stats\n",
    "from pyrocov.stats import normal_log10bf\n",
    "from pyrocov.util import pretty_print, pearson_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matplotlib params\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "matplotlib.rcParams['figure.figsize'] = [8, 8]\n",
    "matplotlib.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "matplotlib.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'Avenir', 'DejaVu Sans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/gisaid.columns.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "print(\"Loaded data from {} samples\".format(len(columns[\"lineage\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checking case count time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(weekly_cases, lw=1, alpha=0.5)\n",
    "    plt.yscale(\"symlog\", linthresh=10)\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlim(0, len(weekly_cases) - 1)\n",
    "    plt.xlabel(\"week after 2019-12-01\")\n",
    "    plt.ylabel(\"confirmed cases\");\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(weekly_strains.sum(-1), lw=1, alpha=0.5)\n",
    "    plt.yscale(\"symlog\", linthresh=10)\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlim(0, len(weekly_cases) - 1)\n",
    "    plt.xlabel(\"week after 2019-12-01\")\n",
    "    plt.ylabel(\"sequenced samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations = set(location_id)\n",
    "# N_usa = sum(1 for k in locations if \"/ USA /\" in k)\n",
    "# N_uk = sum(1 for k in locations if \"/ United Kingdom /\" in k)\n",
    "# N_other = len(locations) - N_usa - N_uk\n",
    "# print(N_usa, N_uk, N_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll account for epidemiological dynamics in the form of random drift on top of our logistic growth model. Since random drift is inversely proportional to the local number of infections, we'll need a new data source for the number of infections in each region. We'll use JHU's confirmed case counts time series as a proxy for the number of total infections in each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = torch.load(\"results/mutrans.pt\", map_location=\"cpu\")\n",
    "first_key = list(fits.keys())[0]\n",
    "for key in fits:\n",
    "    print(key)\n",
    "fits[first_key].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fit in fits.values():\n",
    "    print(fit[\"weekly_strains_shape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is really just the second fit\n",
    "best_fit = list(fits.values())[1]\n",
    "#pretty_print(best_fit, max_items=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale `coef` by 1/100 in all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALREADY_SCALED = set()\n",
    "\n",
    "def scale_tensors(x, names={\"coef\"}, scale=0.01, prefix=\"\"):\n",
    "    if id(x) in ALREADY_SCALED:\n",
    "        return\n",
    "    if isinstance(x, dict):\n",
    "        for k, v in list(x.items()):\n",
    "            if k in names:\n",
    "                print(f\"{prefix}.{k}\")\n",
    "                x[k] = v * scale\n",
    "            elif k == \"diagnostics\":\n",
    "                continue\n",
    "            else:\n",
    "                scale_tensors(v, names, scale, f\"{prefix}.{k}\")\n",
    "    ALREADY_SCALED.add(id(x))\n",
    "                \n",
    "scale_tensors(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.hist(best_fit[\"params\"][\"local_time\"].reshape(-1).numpy(), bins=50, density=True)\n",
    "plt.xlabel(\"local time shift\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assess model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fits():\n",
    "    for key, fit in fits.items():\n",
    "        weekly_strains = fit['weekly_strains']\n",
    "        num_nonzero = int(torch.count_nonzero(weekly_strains))\n",
    "        median = fit.get(\"median\", fit.get(\"mean\", {}))\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        time = np.arange(1, 1 + len(fit[\"losses\"]))\n",
    "        plt.plot(fit[\"losses\"], \"k--\", label=\"loss\")\n",
    "        locs = []\n",
    "        grads = []\n",
    "        for name, series in fit[\"series\"].items():\n",
    "            rankby = -torch.tensor(series).log1p().mean().item()\n",
    "            if name.startswith(\"Guide.\"):\n",
    "                name = name[len(\"Guide.\"):].replace(\"$$$\", \".\")\n",
    "                grads.append((name, series, rankby))\n",
    "            elif name.endswith(\"_centered\") or name == \"local_time\":\n",
    "                grads.append((name, series, rankby))\n",
    "            elif name != \"loss\":\n",
    "                locs.append((name, series, rankby))\n",
    "        locs.sort(key=lambda x: x[-1])\n",
    "        grads.sort(key=lambda x: x[-1])\n",
    "        for name, series, _ in locs:\n",
    "            plt.plot(time, series, label=name)\n",
    "        for name, series, _ in locs:\n",
    "            plt.plot(time, series, color=\"white\", lw=3, alpha=0.3, zorder=-1)\n",
    "        for name, series, _ in grads:\n",
    "            plt.plot(time, series, lw=1, alpha=0.3, label=name, zorder=-2)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlim(1, len(fit[\"losses\"]))\n",
    "        plt.legend(loc=\"upper left\", fontsize=8)\n",
    "        plt.xlabel(\"SVI step (duration = {:0.1f} minutes)\".format(fit[\"walltime\"]/60))\n",
    "        loss = np.median(fit[\"losses\"][-201:]) / num_nonzero\n",
    "        scalars = \" \".join([f\"L={loss:0.6g}\"] + [\n",
    "            \"{}={:0.3g}\".format(\n",
    "                \"\".join(p[0] for p in k.split(\"_\")).upper(), v\n",
    "            )\n",
    "            for k, v in median.items()\n",
    "            if v.numel() == 1\n",
    "        ])\n",
    "        plt.title(\"{} ({})\\n{}\".format(key[0], scalars, key[-1]))\n",
    "plot_fits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import mutrans_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload the import library helpers\n",
    "importlib.reload(mutrans_helpers)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(fits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mutrans_helpers)\n",
    "# Plot the forecasts of a specific model\n",
    "k = list(fits.keys())\n",
    "max_days = k[3]\n",
    "fit = fits[k[3]]\n",
    "\n",
    "fc1 = mutrans_helpers.generate_forecast(\n",
    "    fit=fit\n",
    "    queries=[\"England\", \"USA / California\", \"Brazil\"])\n",
    "\n",
    "mutrans_helpers.get_forecast_values(forecast=fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecasts of a specific model\n",
    "k = list(fits.keys())\n",
    "max_days = k[3]\n",
    "fit = fits[k[3]]\n",
    "\n",
    "fc1 = mutrans_helpers.generate_forecast(\n",
    "    fit=fit, \n",
    "    queries=[\"England\", \"USA / California\", \"Brazil\"])\n",
    "\n",
    "mutrans_helpers.plot_forecast(\n",
    "    forecast=fc1, \n",
    "    filename= f\"results/max_days_{max_days}.png\", \n",
    "    plot_fit=True, \n",
    "    plot_fit_ci=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    max_days = k[3]\n",
    "    fit = fits[k]\n",
    "    fc1 = generate_forecast(fit=fit, queries=[\"England\", \"USA / California\", \"Brazil\"])\n",
    "    plot_forecast(forecast=fc1, filename= f\"results/max_days_{max_days}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in fits.keys():\n",
    "    max_days = k[8]\n",
    "    fit = fits[k]\n",
    "    fc1 = generate_forecast(fit=fit, queries=[\"England\", \"USA / California\", \"Brazil\"])\n",
    "    plot_forecast(forecast=fc1, filename= f\"results/max_days_{max_days}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in len(fits)\n",
    "best_fit = list(fits.values())[8]\n",
    "forecast1 = generate_forecast(fit=best_fit, queries=[\"England\", \"USA / California\", \"Brazil\"])\n",
    "plot_forecast_2(forecast=forecast1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fit = list(fits.values())[5]\n",
    "selected_fit[\"mean\"][\"probs\"].shape\n",
    "# T,P,S shape\n",
    "\n",
    "plot_forecast(selected_fit,\n",
    "              queries=[\"England\", \"USA / California\", \"Brazil\"],\n",
    "              num_strains=10,\n",
    "              filenames=[\"paper/forecast.png\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
