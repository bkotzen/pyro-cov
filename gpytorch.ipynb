{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring GPyTorch & KeOps for determinants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch gpytorch pykeops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpytorch import lazy\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive dense implementation\n",
    "\n",
    "Let us begin by computing the partition function of a phylogeny-constrained spanning tree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3000  # number of leaves\n",
    "d = 10  # embedding dimension\n",
    "\n",
    "V = torch.arange(n)\n",
    "U = torch.arange(n, 2 * n - 1)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "t_V = torch.randn(n)\n",
    "t_U = torch.randn(n - 1) - 1\n",
    "t = torch.cat([t_V, t_U])\n",
    "\n",
    "z = torch.randn(2 * n - 1, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = t[:, None] - t[None, :]\n",
    "abs_dt = dt.abs().clamp(min=1e-2)  # avoid nans\n",
    "dz = z[:, None] - z[None, :]\n",
    "w = dz.pow(2).sum(-1).div(abs_dt).mul(-0.5).exp() / abs_dt.pow(d / 2)\n",
    "\n",
    "# Exclude leaf-leaf edges.\n",
    "is_leaf = torch.cat([torch.ones(n), torch.zeros(n - 1)])\n",
    "w = w * (1 - is_leaf * is_leaf[:, None])\n",
    "\n",
    "# Exclude internal-leaf edges that are out of order.\n",
    "ooo = is_leaf[:, None] * (1 - is_leaf) * (dt <= 0).float()\n",
    "w = w * (1 - ooo - ooo.transpose(-1, -2))\n",
    "\n",
    "L = w.sum(dim=-1).diag_embed() - w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 132 ms, total: 3.01 s\n",
      "Wall time: 2.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10864.2109)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "L[:-1, :-1].logdet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 159 ms, total: 2.04 s\n",
      "Wall time: 1.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5432.1054)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "L[:-1, :-1].cholesky().diag().log().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up using GPyTorch's approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_ = lazy.NonLazyTensor(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 10.7 ms, total: 1.3 s\n",
      "Wall time: 1.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(11485.1592)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "L_[:-1, :-1].logdet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce memory using KeOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "if False:  # TODO\n",
    "    t_ = LazyTensor(t)\n",
    "    z_ = LazyTensor(z)\n",
    "    \n",
    "    dt = t_ - t_.transpose(-1, -2)\n",
    "    abs_dt = dt.abs().clamp(min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
